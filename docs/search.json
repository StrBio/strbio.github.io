[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "StrBio UAM",
    "section": "",
    "text": "This is a Quarto site containing the materials for the Structural Bioinformatics course in the Master’s Degree in Bioinformatics & Computational Biology @UAM. All these materials are open access and shared under CC BY-NC license. These materials were originally elaborated for the 2022 course edition and is subsequently revised each year. The current Course syllabus for year 2024-2025 can be found here (in Spanish). Detailed academic information about the course contents, dates and assessment only can be found at the UAM Moodle site.\n\n\n\n\n\n\nNote\n\n\n\nThis is primarily an introductory course (3 ECTS), designed to offer a general overview as well as tools and resources necessary for initiating SB research projects. Consequently, many fundamental concepts in protein biophysics, scripting tools for SB, and deep-learning methods will only be briefly covered.\n\n\nIn addition to some already classic books, reviews, and articles referenced, the content also draws heavily on the work of others who have generously shared their course materials, tips, and resources on their blogs or websites, as well as discussions on Twitter, especially during the Alphafold2 revolution in 2020-2021. Notable contributions from Alexandre Bovin, Sergey Ovchinnikov, Martin Steinegger and Carlos Outeiral, among many others. Every effort has been made to acknowledge and link to these contributions; however, I apologize in advance for any that may have been inadvertently omitted.\nThe course includes three hands-on exercises designed to guide you through using Pymol to visualize molecules and model proteins via homology modeling and AlphaFold. Additionally, several exercises and questions are highlighted in green throughout the sections to encourage you to reflect on the knowledge and skills acquired and to delve deeper into interpreting the results. I suggest you review also the Structural Bioinformatics exercises from Pontificia Universidad Católica de Chile, detailed in Engelberger et al. (2021): https://github.com/pb3lab/ibm3202\n\n\n\n\n\n\nUnder construction\n\n\n\nPlease note that this website is a draft that is constantly under revision during the semester (May 2025). Any feedback, help, or suggestions would be greatly appreciated.\n\n\n\n\n\nPlease let me know if you find some mistake or a missing reference. Definitely, I’ll appreciate any suggestion, request or correction. You can reach me by email, (f.k.a. Twitter) or .",
    "crumbs": [
      "StrBio UAM"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Structural Bioinformatics 2022-23",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Structural Bioinformatics (SB) is a broad discipline that encompasses data resources, algorithms, and tools for investigating, analyzing, predicting, and interpreting biomacromolecular structures Paiva et al. (2022). In this course, we will specifically focus on protein structural bioinformatics, including visualization and analysis of the structure of biomacromolecules as well as the prediction of protein structures and complexes. The premise of SB is that high-resolution structural information about biological systems enables precise reasoning about their functions and the effects of modifications and perturbations.\nThe goals of SB require at least four different research lines (see Chapter 1 in Gu and Bourne (2009)):\n\nVisualization: Dealing with one or many complex structures and integrating various sources of information such as sequences, structural data, electrostatic fields, locations of functional sites, and areas of variability.\nClassification: Grouping similar structures hierarchically to identify common origins and diversification paths. Similar to other fields of biology classification is tedious but required to understand the structural space.\nPrediction of structures remains an area of keen interest and a field of research itself. As we will see below, the number of different sequences is much higher than the availability of structures, which make prediction an essential and useful tool.\nSimulation. Experimentally obtained structures are primarily static structural models (see warning below). However, the properties of these molecules are often the results of their dynamic motions. The definition of energy functions that govern the folding of proteins and their subsequent stable dynamics can be analyzed by molecular dynamics simulations, although computation capacities may be limiting to reach a biologically relevant timescales.\n\nPowered by vast amounts of data and significant technical advances, the field has undergone a substantial transformation over the past twenty years The enhancement of experimental capabilities to analyze the structure of proteins and other biological molecules and structures (see Callaway (2020)) and the advancement of Artificial Intelligence (AI)-assisted structure prediction have substantially increased the ability of life-science researchers to address various questions concerning protein diversity, evolution, and function. This transformation has boosted in the last 5 years, and its implications for biology, biotechnology, and biomedicine remain largely unpredictable.",
    "crumbs": [
      "Background",
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#warning-for-future-structural-biologists",
    "href": "intro.html#warning-for-future-structural-biologists",
    "title": "Introduction",
    "section": "Warning for future structural biologists",
    "text": "Warning for future structural biologists\n\n\n\nCeci n’est pas une proteine. Source: https://swissmodel.expasy.org/static/course/files/PartIII_quality_assesment.pdf\n\n\nThe surrealist Belgian painter René Magritte created a collection of surrealistic paintings entitled La trahison des images (1928–1929). The most renowned of those paintings show a smoking pipe and the following caption underneath: “Ceci n’est pas une pipe” (This is not a pipe). Yes, indeed! It is actually the painting of a pipe.\nSimilarly, a picture of a protein, or a PDB file with the coordinates of a protein structure, is not a protein. It is a representation of ONE structure. Even experimentally determined structures have two main limitations that we should always keep in mind: (1) they are a fixed structure whereas proteins in vivo are flexible and dynamic and (2) they are subjected to experimental error and they often contain regions of low reliability. Moreover, even experimentally obtained macromolecular structures are to some degree models, with a variable ratio between experimental data and computational prediction to match the experimental data (X-ray diffraction, cryo-EM density maps, NMR, SAXS, FRET…) with previously known structures or prediction models. That does not mean that protein structures are useless, they can be very useful, but we must be aware of the limitations as well as the applications."
  },
  {
    "objectID": "homology.html",
    "href": "homology.html",
    "title": "Homology Modeling",
    "section": "",
    "text": "The number of protein sequences in databases growth exponentially during the last decades, particularly after the revolution of high throughput sequencing methods.\n\n\n\nFigure 1: Number of entries in UniProt/TrEMBL.\n\n\nHowever, experimental determination of 3D protein structures is often difficult, time-consuming, and subjected to limitations, such as experimental error, data interpretation and modeling new data on previously released structures. Thus, despite substantial efforts that started at the beginning of the 21st century to implement high-throughput structural biology methods (see for instance Manjasetty et al. 2008), the availability of protein structures is more than 1,000 times less than the number of sequences (&gt;250M sequences for Uniprot and ∽205k structures in RCSB Protein Databank in September 2023). This difference is called the protein sequence-structure gap and it is constantly widening (Muhammed and Aki-Yalcin 2019), especially if we consider the sequences from metagenomics databases not available in Uniprot.\n\n\n\nFigure 2: Number of macromolecular structures in RCSB PDB database (accessed 19th September 2023).\n\n\nThus, an accurate prediction of the 3D structure of any given protein is needed to make up for the lack of experimental data.\n\n\nThe properties of the amino acids determine the Φ and Ψ angles that eventually shape the higher structural levels. However, protein folding can be more complex, as it should be coupled with protein synthesis.\nOne can imagine that the complexity and diversity of protein structures in nature can be enormous. Indeed, John Kendrew and his co-workers seemed very disappointed in the determination of the first three-dimensional globular structure, the myoglobin in 1958 (Kendrew et al. 1958):\n\nPerhaps the most remarkable features of the molecule are its complexity and its lack of symmetry. The arrangement seems to be almost totally lacking in the kind of regularities which one instinctively anticipates, and it is more complicated that has been anticipated by any theory of protein structure.\n\nNot much later, in 1968, Cyrus Levinthal (1922–1990) published the so-called Levinthal’s paradox, stating that proteins fold in nano/milliseconds, but even for small peptides it will take a huge time to test the astronomical number of possible conformations. Say a 100 aa small protein; it will have 99 peptidic bonds and 198 different phi and psi angles. Assuming only 3 alternative conformations for each bond, it will yield 3198 (= 2.95 x 1095) possible conformations. If we design a highly efficient algorithm that tests 1 conformation per nanosecond:\n 2.95 x 1085 secs = 9x1067 billions years\nConsidering that the age of the universe is 13.8 billion years, predicting protein structures does not seem an easy task.\nIn this context, a very simple experiment 50 years ago, led some light on the protein folding mechanism. Cristian Anfisen was able to completely denature (unfold) the Ribonuclease A, by the addition of reducing agents and urea under heat treatment, and subsequently switch to normal conditions that allow the protein to re-fold fully functional. This experiment indicates that the amino acid sequence dictates the final structure. Notwithstanding some relevant exceptions, this has been largely confirmed.\n\n\n\nFigure 3: The Anfinsen Dogma: Amino acid sequence dictated the final structure. From Anfinsen (1973) .\n\n\nOne can imagine that in vivo native structures of proteins look-alike the lowest free energy conformation, i.e., the global energy minimum. That is the basis of the funnel model of protein folding, which assumes that the number of possible conformations is reduced when a local energy minimum is achieved, constituting a path for the folding process.\n\n\n\nFigure 4: Schematic diagram of a protein folding energy landscape according to the funnel model. Denatured molecules at the top of the funnel might fold to the native state by a myriad of different routes, some of which involve transient intermediates (local energy minima) whereas others involve significant kinetic traps (misfolded states). From Radford (2000).\n\n\n\n\n\n\n\n\nConclusion\n\n\n\nPrediction of protein structures is possible, as protein folding relies only on the protein sequence, but it will require virtually infinite time and computational resources …or highly efficient ones, as we will see.\n\n\nHomology modeling is one of the most convenient tricks to get around this limitation. Basically, the strategy is to add more layers of additional information to amino acid properties, namely evolutionary conservation of sequences and structures.\nVery often, you already have some information about your protein before you create models. For example, if it is an enzyme, you may have discovered the catalytic residues or the substrate interaction region. It is also advisable to look in the literature, in particular to see if there is a companion paper to the corresponding PDB structure(s) that may be available or that you may be able to find and use as a template(s) for modeling."
  },
  {
    "objectID": "homology.html#step-12.-template-search-and-align.",
    "href": "homology.html#step-12.-template-search-and-align.",
    "title": "Homology Modeling",
    "section": "3.1 Step 1+2. Template search and align.",
    "text": "3.1 Step 1+2. Template search and align.\n\n3.1.0.1 Where can we search?\nTemplate searching consists in finding a protein with known structure that has a sequence similar to our protein. As we mentioned above, the RCSB Protein Data Bank (PDB) is the largest database of protein structures, so we can search templates by comparing the sequence of our protein with the sequence of all the proteins in PDB. However, PDB was constructed to contain all the macromolecular structures, not for searching templates for modeling. Similar to other end-to-end software, SWISS-MODEL has its own curated database, called SMLT (SWISS-MODEL template library). This is based on PDB, updated weekly, and also annotated and indexed to boost searches. As of 6 July 2022, SMLT contains 133,049 unique protein sequences that map to 332,864 biological units (protein structures classified by their quaternary structure).\nNow, you first need your sequences. A protein sequence database like Uniprot or NCBI Protein, is a good place for this task.\nIf you want to cheat yourself, I give you the HAdV-2pol and NEIL2 sequences.\n\n\n3.1.0.2 How can we search accurately and fast?\n\n\n\n\n\nQuery-template alignment is the base for homology modeling (Kelley (2009a))\n\n\nFinding templates require comparing sequences, thus an accurate and powerful alignment method is essential. Comparing one protein sequence with a whole database is time-consuming, as you will compare with totally unrelated proteins, which is a loss of resources. Two basic improvements increased the template search capacity, (1) the introduction of secondary structure (SS) by comparing SS predictions of the query protein and the secondary structures of the protein database, and (2) the use of profiles to make easier the comparison. Profiles are a mathematical way to summarize a multiple sequence alignment in which the frequency of each amino acid at each position is quantified. This allows the identification of highly conserved positions that not only define the protein function but also the fold. For instance, glycines at the end of each beta-strand or a pattern of polar residues that favor alpha-helices. A previous comparison of the query sequence with a database of sequences will allow us to include evolutionary information about it. Therefore, we moved from a requirement of >30% identity to obtain good models before the implementation of profiles, to good models even with ⁓20% identity or below. Moreover, the generation of profiles also facilitates clustering of the search database, reducing search time. The implementation of these capacities led to the implementation of the so-called fold recognition in homology modeling.\n\n\n\n\n\nFrom sequence vs. sequence search to profile-profile comparison (Kelley (2009b))\n\n\nTemplate searches in SWISS-MODEL are carried out with HHblits (Remmert et al. (2011)), a specific profile-profile method. We could search for templates also with Blast or other profile-profile methods, like Psi-BLAST, HHPred, or JackHMMER. Then templates are ranked by two different parameters, GMQE (global model quality estimate) and QSQE (quaternary structure quality estimate). Briefly, GMQE uses probability functions to assess several properties of the target-template alignment (sequence identity, sequence similarity, HHblits score, the agreement between predicted secondary structure of target and template, the agreement between predicted solvent accessibility between target and template; all normalized by alignment length) to predict the expected quality of the resulting model. QSQE assesses the oligomeric state probability of the model.\nNow, paste your sequences and click on Search.\nNote: If you click on “Build Model”, it will directly use the top-ranked template, so you’ll miss some fun, but you can go back for that later on if you change your mind.\n\n\n\nSWISS-MODEL modeling start\n\n\nBefore building the models, could you foresee which of our queries will give rise to a better model? Why?"
  },
  {
    "objectID": "homology.html#step-3.-model-building.",
    "href": "homology.html#step-3.-model-building.",
    "title": "Homology Modeling",
    "section": "Step 3. Model Building.",
    "text": "Step 3. Model Building.\nBy default, SWISS-MODEL will provide 50 ranked possible templates. The output also contains information about the method and resolution of the templates, the % of identity (and alignment coverage) with the query sequence, and the GMQE and QSQE.\nThe top template is marked by default and it likely will give the best model, but it is also interesting to try some alternative templates depending on the downstream application of the model (see below). For instance with a different substrate/cofactor that can have a key role in the protein function or with different coverage or % identity.\nOnce the template(s) is selected, model coordinates are constructed based on the alignment of the query and template sequence using ProMod3 module (Studer et al. 2021). SWISS-MODEL uses a fragment assembly, which is also the bases of Fold-recognition or Threading methods (see Threading section). Other programs, like Modeller, are based in the satisfaction of general spatial restraints (Giacomo Janson et al. 2019). Modeller is a command-line tool that allow full customization of the modeling, which requires more knowledge about the process but can be very useful for some types of proteins (see (Webb and Sali 2017)). However, it has been implemented in some online servers (ModWeb) and user-friendly applications, including ChimeraX and Pymol (Pymod plugin, G. Janson and Paiardini (2021)). Modeller can be also called from the HHPred output (if you included PDB as a searchable database), which is very convenient to model remote homologs using several templates in a few minutes.\nFragment assembly will use the template core backbone atoms to build a core structure of the model, leaving non-conserved regions (mostly loops) for later. Loops modeling includes the use of a homologs subset of a dedicated loop database, Monte Carlo sampling as a fallback and even ab initio building or missing loops.\n\n\n\nFigure 13: Backbone and loop modeling. From Expasy Protein Structure, Comparative Protein Modelling, and Visualisation.\n\n\nThen, positioning of side chain of non conserved amino acids is undertook. The goal is finding the most likely side chain conformation, using template structure information, rotamer libraries (from a curated set known protein structures) and energetic and packaging criteria. If many side chains have to be placed in the structure it will lead to a “chicken and egg problem”, as positioning one rotamer would affect others. That means that identification of possible hydrogen bonds between residues side chains and between side chains and the backbone reduce the optimization calculations. At the end of the day, the more residues correctly positioned, the best model.\n\n\n\nFigure 14: Side chain modeling. From CMBI Seminars on Bioinformatics.\n\n\nFinally, a short energy minimization is carried out to reduce the unfavorable contacts and bonds by adapting the angle geometries and relax close contacts. This energy minimization step or refinement can be useful to achieve better models but only when the folding is already accurate."
  },
  {
    "objectID": "homology.html#step-4.-result-assessing.",
    "href": "homology.html#step-4.-result-assessing.",
    "title": "Homology Modeling",
    "section": "Step 4. Result assessing.",
    "text": "Step 4. Result assessing.\nThe computer always give you a model but it doesn’t mean that you have a model that makes sense. How can we know if we can rely on the model? Output models are colored in a temperature color scale, from navy blue (good quality) to red (bad quality). That can help us to understand our model in a first sight. Also, this is an interactive site and you can zoom-in, zoom-out the model. Many other features are available to work on your model. For instance, you can compare multiple models, you can change the display options. You can also download all the files and reports on the “Project Data” button.\n\n\n\nFigure 15: NEIL2 model created with SWISS-MODEL (July 2022)\n\n\nThere is also a “Structure Assessment” option. This provide you a detailed report of the structural problems of your model. You can see Ramachandran plots that highlight in red the amino acid residues with abnormal phi/psi angles in the model and a detailed list of other problems.\nThe GMQE is updated to the QMEAN Zscore and QMEANDisCo (Studer et al. 2020). The QMEAN Z-score or the normalized QMEAN score indicates how the model is comparable to experimental structures of similar size. A QMEAN Z-score around 0 indicates good agreement, while score below -4.0 are given to models of low quality. Besides the number, a plot shows the QMEAN score of our model (red star) within all QMEAN scores of experimentally determined structures compared to their size. Overall, the Z-score is equivalent to the standard deviation of the mean.\n\n\n\nFigure 16: Per-residue QMEANDisCo scores are mapped as red-to-green colour gradient on a model of lbp-8 in Caenorhabditis elegans (UniProtKB: O02324, PDB: 6C1Z). Distance constraints have been constructed from an ensemble of experimentally determined protein structures that are homologous to lbp-8. The inset depicts two example constraints between residues marked with colour-coded spheres in the model. From Studer et al. (2020).\n\n\nThe QMEANDisCO was implemented in SWISS-MODEL in 2020 and it is a powerful, single parameter that combines statistical potentials and agreement terms with a distance constraints (DisCo) to provide a consensus score. DisCo evaluates consistencies of pairwise CA-CA distances from a model with constraints extracted from homologous structures. All scores are combined using a neural network trained to predict per-residue scores. We can check a global score, but also a local score for each residue, that help us to understand which regions of the model are more likely to accurately folded (i.e. they are more reliable).\n\n\n\nFigure 17: HAdV-2 DNA polymerase model obtained with SWISS-MODEL (July 2022).\n\n\nQMEANDisCo can be used to analyze models obtained with other methods in order to make them comparable (note that you can use QMEANDisCo for models obtained with any method, you just need a .pdb file). There are other independent model assessing tools commonly used to assess protein models, like VoroMQA (Olechnovič and Venclovas 2017) or MoldFold (McGuffin et al. 2021). VoroMQA is very quick method that combines the idea of statistical potentials (i.e. a knowledge-based score function) with the use of interatomic contact areas to provide a score in the range of [0,1]. When applied to PDB database, most of the high-quality experimentally-based structures have a VoroMQA score &gt;0.4. Thus, if the score is greater than 0.4, then the model is likely good and models with score &lt;0.3 are likely bad ones. Models with score 0.3-0.4 are uncertain and should not be classified with VoroMQA. On the other hand, ModFold is a meta-tool that provides you a very detailed report (and parseable files) with local and global scores, but it can take hours/days to obtain the result, so tend to use it only with selected models.\n\n\n\n\n\n\nAlphaFold DB models\n\n\n\nModels from the AlphaFold DB are appended to the available structures / models if available. For these models we use the confidence values provided by AlphaFold (pLDDT) rescaled to be between 0 and 1. Since both pLDDT and QMEANDisCo are trained to predict lDDT (Cα-only for pLDDT and all-atom for QMEANDisCo) and are displayed in the same range, they should be considered comparable (From https://swissmodel.expasy.org/docs/repository_help.)\n\n\nAnother key parameter that you should know if you want to compare protein structures is the alpha carbon RMSD (see Structure alignment section). Any protein structural alignment will give you this parameter as an estimation of the difference of the structures. You can align structure with many online servers, like RCSB, FATCAT2 or using molecular visualization apps, including Mol*, ChimeraX or PyMOL (see Protein Structure Display section).\n\nWhich model is better? Which regions are more difficult to model? Why?"
  },
  {
    "objectID": "homology.html#corollary",
    "href": "homology.html#corollary",
    "title": "Homology Modeling",
    "section": "Corollary: What can I do with my model and what I cannot?",
    "text": "Corollary: What can I do with my model and what I cannot?\n\n\n\nFigure 18: Accuracy and application of protein structure models (in 2001). From .\n\n\nA big power entails a big responsibility. The use of models entails a precaution and a need for experimental validation. However, knowing the limitations of our model is required for a realist use of it; and limits are defined by the model quality.\nThe accuracy of a comparative model is related to the percentage sequence identity on which it is based. High-accuracy comparative models can have about 1-2 Å root mean square (RMS) error for the main-chain atoms, which is comparable to the accuracy of a nuclear magnetic resonance (NMR) structure or an x-ray structure. These models can be used for functional studies and the prediction of protein partners, including drugs or other proteins working in the same process. Also, for some detailed studies, it would be convenient to refine your model by Molecular Dynamics and related methods towards a native-like structure. I suggest checking the review by Adiyaman and McGuffin (2019) on this topic.\nOn the contrary, low-accuracy comparative models are based on less than 20-30% sequence identity, hindering the modeling capacity and accuracy. Some of these models can be used for protein engineering purposes or to predict the function of orphan sequences based on the protein fold (using Dali or Foldseek).\nAs mentioned above, it also advisable to check the template structures and read the papers describing them in order to squeeze all the information from your model.\nWhat do you think you could use our models of NEIL2 and HAdV-2pol?"
  },
  {
    "objectID": "homology.html#template",
    "href": "homology.html#template",
    "title": "Homology Modeling",
    "section": "Step 1+2. Template search and align.",
    "text": "Step 1+2. Template search and align.\n\nWhere can we search?\nThe template searching consists in finding a protein with known structure(s) with a sequence related to our protein. As we mentioned earlier, the RCSB Protein Data Bank (PDB) is the largest database of protein structures. Thus, we can search for templates by comparing the sequence of our protein with the sequence of all proteins in the PDB. However, the PDB was created as a repository to contain all the macromolecular structures, not to search templates for modeling. Similar to other end-to-end software, SWISS-MODEL has its own curated database, the SMLT (SWISS-MODEL template library). This is based on profiles alignments from the PDB, is updated weekly, and is also annotated and indexed to facilitating searching. As of September 13, 2023, SMLT contains 145,813 unique protein sequences that can map into 375,008 biological units. Since 2023, SWISS-MODEL also searches in the AlphaFold DB.\nNow, you first need your sequences. A protein sequence database like Uniprot or NCBI Protein, is a good place for this task.\nIf you want to cheat yourself, just follow the links to HAdV-2pol and NEIL2 sequences.\n\n\nHow can we search accurately and fast?\n\n\n\nFigure 10: Query-template alignment is the base for homology modeling (Kelley 2009)\n\n\nTo find templates, sequences must be compared, so an accurate and powerful alignment method is essential. Comparing a protein sequence to an entire database is time consuming because you are comparing to completely unrelated proteins, which means a loss of resources. Two fundamental improvements have increased the capacity of template search: (1) the introduction of secondary structure (SS) by comparing SS predictions of the query protein and secondary structures of the protein database, and (2) the use of profiles to facilitate the comparison. Profiles are a mathematical method of summarizing a multiple sequence alignment that quantifies the probability of each amino acid at each position. A particular type of profile Hidden Markov Models (HMM) are very useful for searching databases for similar sequences. Transition probabilities (i.e., the probability that a particular amino acid follows another particular amino acid) are also modeled. In addition, HMMs include insertions and deletions of amino acids. These features allow HMMs to model entire alignments in great detail, including very divergent regions, and facilitate the identification of highly conserved positions that define not only protein function but also folding. For example, glycine residues at the end of each beta strand or a pattern of polar residues that favor alpha helices. Prior comparison of the query sequence to a database of sequences allows us to incorporate evolutionary information about the sequence. Therefore, we started from a requirement of &gt;30% identity to obtain good models before the implementation of profiles, to good models even with ⁓20% identity or below. Moreover, the generation of profiles also facilitates clustering of the search database, reducing search time. The implementation of these capacities led to the implementation of the so-called fold recognition in homology modeling.\n\n\n\nFigure 11: From sequence vs. sequence search to profile-profile comparison (Kelley 2009).\n\n\nTemplate searching in SWISS-MODEL has evolved over the years toward more accurate results. Currently, this is done with HHblits (Remmert et al. 2011), a iterative profile-profile method. We can also search for templates using Blast or other profile-profile methods, like Psi-BLAST, HHPred, or JackHMMER. Then, the templates are ranked between 0 and 1 using two different numerical parameters: GMQE (global model quality estimate) and QSQE (quaternary structure quality estimate). Briefly, GMQE uses likelihood functions to evaluate various properties of the target-template alignment (sequence identity, sequence similarity, HHblits score, the agreement between the predicted secondary structure of target and template, the agreement between the predicted solvent accessibility between target and template; all normalized by the alignment length) to predict the expected quality of the resulting model. QSQE evaluates the likelihood of the oligomeric state of the model.\n\n\n\nFigure 12: SWISS-MODEL modeling start. Just paste your sequences and click on Search.\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you click on “Build Model”, it will directly use the top-ranked template, so you’ll miss some fun, but you can go back for that later on using the “Templates” tab.\n\n\n\nCould you foresee which of our queries will give rise to a better model? Why?"
  },
  {
    "objectID": "ai.html",
    "href": "ai.html",
    "title": "Protein modeling in the AlphaFold era",
    "section": "",
    "text": "Every two years since 1994, groups in the field of structural bioinformatics have conducted a worldwide experiment in which they predict a set of unknown protein structures in a controlled, blind test-like competition and compare their results with the experimentally obtained structures. That is the CASP or Critical assessment of Protein Structure Prediction.\n\n\n\nFigure 1: Comparative Z-score of CASP13 participants. The score is based in the GDT_TS (Global distance test).\n\n\nThe best research groups in the field test their new methods and protocols in the CASP. However, at CASP13 (2018), an AI company called Deepmind (Google Subsidiary) entered the scene. Their method, named Alphafold (Senior et al. 2020) clearly won CASP13. Alphafold (v.1) implemented improvements in some recently used approaches and created an entirely new pipeline. Instead of creating contact maps from the alignment and then folding the structure, they used an MRF unit (Markov Random Field) to extract the main features of the sequence and MSA in advance and process all this information into a multilayer NN (called ResNet) that also predicted distance probabilities instead of contacts, resulting in high accuracy. Then, Alphafold uses all the possibly obtained information to create the structure and then improve it by energy minimization (steepest descent method) and substitution of portions with a selected DB of protein fragments.\n\n\n\nFigure 2: Workflow of the first Alphafold method presented in CASP13. MSA stands for multiple sequence alignment; PSSM indicates Position-specific-scoring matrix and MRF stands for Markov Random Field (or Potts model). From the Sergei Ovchinnikov and Martin Steinegger presentation of Alphafold2 to the Boston Protein Design Group (slides and video in the link below).\n\n\nAfter Alphafold, similar methods were also developed and made available to the general public, like the trRosetta (Yang et al. 2020), from the Baker lab, available in Rosetta open source software and in the Robetta server. This led to some controversy (mostly on Twitter) about the open access to the CASP software and later on DeepMind publishes all the code on GitHub."
  },
  {
    "objectID": "ai.html#useful-links",
    "href": "ai.html#useful-links",
    "title": "AI-based protein modeling with Colabfold",
    "section": "Useful links",
    "text": "Useful links\n\nIntroductory article to Neural Networks at the IBM site: https://www.ibm.com/cloud/learn/neural-networks\nColabFold Tutorial presented presented by Sergey Ovchinnikov and Martin Steineggerat the Boston Protein Design and Modeling Club (6 ago 2021). [video] [slides].\nPost about Alphafold2 in the Oxford Protein Informatics Group site: https://www.blopig.com/blog/2021/07/alphafold-2-is-here-whats-behind-the-structure-prediction-miracle/\nA very good digest article about the Alphafold2 paper: https://moalquraishi.wordpress.com/2021/07/25/the-alphafold2-method-paper-a-fount-of-good-ideas/"
  },
  {
    "objectID": "ai.html#why-is-alphafold2-so-accurate",
    "href": "ai.html#why-is-alphafold2-so-accurate",
    "title": "AI-based protein modeling with Colabfold",
    "section": "Why is Alphafold2 so accurate?",
    "text": "Why is Alphafold2 so accurate?\nThe phylosophy behind Alphafold and Alphafold2 is treating protein folding problem as a machine learning problem of processing of images. In all these problems, the input to the Deep Learning model is a volume (3D tensor). In case of computer vision, 2D images expand as a volume because of the RGB or HSV channels. Similarly, in the case of distance prediction, predicted 1D and 2D features are transformed and packed into 3D volume with many channels of inter-residue information (Pakhrin et al. 2021).\n\n\n\nFrom the perspective of Deep Learning method development, the problem of protein distogram or real-valued distance prediction (bottom row) is similar to the ‘depth prediction problem’ in computer vision. From (Pakhrin et al. 2021)\n\n\nAlphafold2 can be explained in three independent tasks (see picture below). First, it queries several databases of protein sequences, and constructs an MSA that is used to select templates. In the second part of the diagram, AlphaFold 2 takes the multiple sequence alignment and the templates, and processess them in a transformer. The objective of this part is to extract layers of information to generate residue interaction maps. A better model of the MSA will improve the network’s characterization of the geometry, which simultaneously will help refine the model of the MSA. Importantly, this process is iterative and the number of recycling steps improve the model (the original model uses 48 blocks of cycles).\nThe third part of the pipeline is the structure building module, which use the information from the previous steps to construct a 3D model structure protein of the query sequence. This network will give you a single model, without any energy optimization step.\n\n\n\nOxford Proteins Informatics Group Blog, modified From (Jumper et al. 2021b)\n\n\nAs mentioned above, Colabfold aims to make the process faster by using MMSeqs in the first block. Additionally, the number of recycling steps can also adapated."
  },
  {
    "objectID": "ai.html#corollary-has-levinthals-paradox-folded",
    "href": "ai.html#corollary-has-levinthals-paradox-folded",
    "title": "Protein modeling in the AlphaFold era",
    "section": "Corollary: Has Levinthal’s paradox “folded”?",
    "text": "Corollary: Has Levinthal’s paradox “folded”?\nThe development of Alphafold and the Alphafold structures Database in collaboration with EMBL-EBI has been the origin of a New Era. Scientific publications and journals worldwide published long articles about the meaning of this breakthrough in science and its applications in biotechnology and biomedicine1 and DeepMind claimed to have Solved a 50-years Grand Challenge in biochemistry. The coverage of the protein structure space has been greatly increased (Porta-Pardo et al. 2022).\nHowever, some scientists have claimed that Alphafold2 and RoseTTAfold actually “cheat” a bit as it does not really solve the problem but generate a deep learning pipeline that “bypass” the problem (Pederson 2021). In agreement with that, it has been shown that machine learning methods actually do not reproduce the expected folding pathways while improving the structures during the recycling steps Outeiral, Nissley, and Deane (n.d.).\nIn conclusion, I do believe that Levinthal’s paradox has not been (yet) fully solved, although it seems to be close (Al-Janabi 2022). Moreover, in practical terms it is solved for most of the protein space."
  },
  {
    "objectID": "ai.html#why-is-alphafold2-so-freaking-accurate",
    "href": "ai.html#why-is-alphafold2-so-freaking-accurate",
    "title": "Protein modeling in the AlphaFold era",
    "section": "Why is Alphafold2 so freaking accurate?",
    "text": "Why is Alphafold2 so freaking accurate?\nThe philosophy behind Alphafold and related methods is to treat the protein folding problem as a machine learning problem, similar to image processing. In all of these problems, the input to the Deep Learning model is a volume (3D tensor). In the case of computer vision, 2D images expand as volumes because of the RGB or HSV channels. Similarly, in the case of distance prediction, predicted 1D and 2D features are transformed and packed into a 3D volume with many channels of inter-residue information (Pakhrin et al. 2021).\n\n\n\nFigure 4: From the perspective of Deep Learning method development, the problem of protein distogram or real-valued distance prediction (bottom row) is similar to the ‘depth prediction problem’ in computer vision. From Pakhrin et al. (2021).\n\n\nAlphafold v.2 (from now on, just Alphafold) can be explained as a pipeline with three interconected tasks (see picture below). First, in contrast to Alphafold v.1, the input to Alphafold is a “raw” MSA, i.e., the deep learning network extracts the co-evolutionary information directly from the MSA. It queries several databases of protein sequences and constructs an MSA that is used to select templates. This can be a limiting step, affecting the speed of modeling (see below), but it can be also related to model accuracy, as has been recently shown in CASP15 (Lee et al., n.d.; Peng et al. 2023).\nIn the second part of the diagram, AlphaFold takes the multiple sequence alignment and the templates, and processes them in a transformer. This process has been referred by some authors as inter-residue interaction map-threading (Bhattacharya et al. 2021). The objective of this part is to extract layers of information to generate residue interaction maps. A better model of the MSA will improve the network’s characterization of the geometry, which simultaneously will help refine the model of the MSA. Importantly, in the AF2 Evoformer, this process is iterative and the information goes back and forth throughout the network. At every recycling step, the complexity of the map increases and thus, the model improves (the original model uses 3 cycles). As explained in the great post from Carlos Outerial at the OPIG site:\n\nThis is easier to understand as an example. Suppose that you look at the multiple sequence alignment and notice a correlation between a pair of amino acids. Let’s call them A and B. You hypothesize that A and B are close, and translate this assumption into your model of the structure. Subsequently, you examine said model and observe that, since A and B are close, there is a good chance that C and D should be close. This leads to another hypothesis, based on the structure, which can be confirmed by searching for correlations between C and D in the MSA. By repeating this several times, you can build a pretty good understanding of the structure.\n\nThe third part of the pipeline is the structure building module, which uses the information from the previous steps to construct a 3D model structure protein of the query sequence. This network will give you a single model, without any energy optimization step. Model building is based in a new concept of 3D structures generation, named IPA (Invariant Point Attention) and the use of a curated list of parametrised list of torsion angles to generate the side chains. Earlier attempts to develop and end-to-end method were unsuccessful because the structure representation was not optimal. Even methods implemented after AlphaFold, like RoseTTAFold, use less efficient methods and often predict very quickly and accurately the backbone coordinates but require external programs to generate an all-atoms model\n\n\n\nFigure 5: Oxford Proteins Informatics Group Blog, modified From\n\n\nLike for most of the previous methods Alphafold would give your better results with proteins with related structures known and with a lot of homologs in Uniref databases. However, comparing to nothing, it will likely give you (limited) useful results for the so-called “dark genome”. I work with phages and bacterial mobile elements, and sequencing that is often frustrating as more than 50% of the proteins have no homologous in the database. So you have a bunch of proteins of unknown function… However, as we do know that structure is more conserved than sequence, we may use the structure to find out the function of our dark proteins. There are a few resources for this, I’d suggest you to try FoldSeek (Kempen et al., n.d.) and Dali (Holm 2022) servers. You can upload the PDB file of your model and search for related structures in RCSB PDB database and also in Alphafold database.\n\n\n\n\n\n\nTip\n\n\n\nFoldSeek needs only a few seconds/minutes and is therefore faster than Dali. Therefore, it is better to use Dali for some selected searches that require a double check or a more reliable result, even if it may take a few days.\n\n\nAs mentioned above, Colabfold aims to make the process faster by using MMSeqs in the first block. Additionally, the number of recycling steps can also be adapted. Moreover, different Colabfold notebooks have been developed (and evolved) to allow some customization and other feature, like batch processing of multiple proteins avoiding recompilation and identification of protein-protein interactions (Mirdita et al. 2022).\nAlphafold models can be evaluated by the mean pLDDT, a per-residue confidence metric. It is stored in the B-factor fields of the mmCIF and PDB files available for download (although unlike a B-factor, higher pLDDT is better). The model confidence can vary greatly along a chain so it is important to consult the confidence when interpreting structural features. Very often, the lower confidence fragments are not product of a poor prediction but an indicator of protein disorder (Wilson, Choy, and Karttunen 2022).\nAlphafold also partnered with EMBL-EBI and Uniprot and generated a huge curated database of proteins from model organisms (Varadi et al. 2022), the Alphafold database. This is an amazing resource that may be also very helpful for you. Just consider that this database increased from 48% to 76% the fraction of human proteome with structural data, and also it also means great increases in the case of other model organisms, like, including microorganisms and plants (Porta-Pardo et al. 2022).\n\n\n\nFigure 6: Changes in protein structural coverage in model organisms."
  },
  {
    "objectID": "ai.html#lets-try-alphafold2.",
    "href": "ai.html#lets-try-alphafold2.",
    "title": "State-of-the-art protein modeling (in 2022)",
    "section": "Let’s try Alphafold2.",
    "text": "Let’s try Alphafold2.\nSection under construction!\nAs mentioned above, the grand breakthrough of Alphafold would not have been the same without the Colabfold, a free open tool that made the state-of-the-art of AI-fueled protein prediction available to everyone.\n\n\n\nColabFold GitHub repository\n\n\nThe Colabfold repository on GitHub contains links to several Python “notebooks” developed on Google Colab, a platform to develop and share Python scripts on a Jupyter Notebook format. Notebooks are very important also for reproducibility in computer sciences, as they allow you to have the background and details and the actual code in a single document and also execute it. You can share those notebooks very easily and also update quickly as they are stored in your Google Drive.\nColabfold allow you to run notebooks of Alphafold and RoseTTAfold for specific applications, allowing even to run a bunch of proteins in batch. You can see a more detailed description in Mirdita et al. (2022). We are using the Alphafold2_mmseqs2 notebook, that allow you most of the common features. You need to allow Colab to use your Google account.\n\n\n\nIntroducing your sequence in Colabfold\n\n\nThen paste your sequence and chose a name. For more accurate models you can click “use_amber” option. It will run a short Molecular Dynamics protocol that ultimately optimize the modeling, but it will also take some more time, so better try at home.\nAs you can see, an this is a recent feature, you can also add your own template. That will safe time, but of course without any guarantee. If you have a template of a related protein, like an alternative splicing or a disease mutant, I’d advise you to try with and without the template. You may surprise.\n\n\n\nExecuting Colabfold\n\n\nAt this point, you may execute the whole pipeline or may some more customization. MSA stage can be also optimized to reduce execution time, by reducing database or even by providing your own MSA. Very often you may want to fold a protein with different parameters, particularly in the Advanced Colabfold, which may very convenient to reuse an MSA from a previous run (although they recently updated servers for MMSeqs and made it really faster). If your proteins are in the same operon or by any other reason you think that they should have co-evolved, you prefer a “paired” alignment. But you can always do both.\nAdvanced settings are specially needed for protein-protein complexes. Also the number of recycling steps will improve your model, particularly for targets with no MSA info from used databases. Then you can just get your model (and companion info and plots) in your GDrive or download it.\nWhat do you think is the ideal protein for alphafold2? Do you think homology modeling is dead?"
  },
  {
    "objectID": "pdb.html",
    "href": "pdb.html",
    "title": "Protein Structures",
    "section": "",
    "text": "Figure 1: Ceci n’est pas une proteine. Source: SwissModel site.\n\n\n\nThe surrealist Belgian painter René Magritte created a collection of surrealistic paintings entitled La trahison des images (1928–1929). The most famous of these paintings show a smoking pipe with the following caption underneath: “Ceci n’est pas une pipe” (This is not a pipe). Yes, indeed! It is actually a painting of a pipe.\n\n\n\n\n\n\nWarning for current and future structural biologists\n\n\n\nA picture of a protein, or a computer file containing the coordinates of a protein structure, is not a protein. It is a representation of ONE possible structure of that protein.\n\n\nEven experimentally determined structures have two major limitations that we should always keep in mind: (1) they are a fixed structure (except RMN-based), whereas proteins in vivo are flexible and dynamic and (2) they are subject to experimental error and often contain low confidence regions (see Section 3 below). Moreover, even experimentally determined macromolecular structures are to some extent models, with a variable ratio between experimental data and computational predictions to match the experimental data (X-ray diffraction, cryo-EM density maps, NMR, SAXS, FRET…) with previously known structures or models. Of course, this does not mean that protein structures are useless, they can be very useful, but we need to be aware of both the limitations and the applications.",
    "crumbs": [
      "Background",
      "Protein Structures"
    ]
  },
  {
    "objectID": "ddbb.html",
    "href": "ddbb.html",
    "title": "Protein Databases",
    "section": "",
    "text": "As in the case of sequences, comparison and alignment of protein structures is a fundamental and widely used task in computational structure biology. The identification and statistical measure of the similarities between two or more structures allow their classification and infer functional and evolutionary relationships. Moreover, this process is essential during protein modeling, allowing to identify, assess, and select intermediate models.\nIt is also important to clear up any possible confusion between alignment and superposition, as they are often interchanged in the literature. An structural alignment tries to identify similarities and differences between two structures, while structure superposition displays the structures using a given criteria, usually from a previous structural alignment. Thus, based on that criteria, superposition tries to minimize the distance between structures by finding a transformation that produces either the lowest root-mean-square deviation (RMSD) or the maximal equivalences within an RMSD cutoff. The RMSD can be calculated for any pair of molecules. Regarding proteins, we usually refer to the RMSD of the alpha-carbons. A better alignment will allow a better superposition. Thus, although alignment and superposition are two different processes, the RMSD can be used as an indication of both (the lowest RMSD, the best alignment/superposition).\n\n\n\nFigure 1: Structural alignment of three different AP endoncleases with the cealign algorithm implemented in Pymol. The RMSD and the number of aligned residues for each pair of structures is indicated."
  },
  {
    "objectID": "ddbb.html#sequence-databases",
    "href": "ddbb.html#sequence-databases",
    "title": "Protein Databases",
    "section": "Sequence databases",
    "text": "Sequence databases\n\nUniprot\nThe Uniprot databases are maintained by the Uniprot consortium, created in 2002 by EMBL-EBI, SIB, and PIR. Uniprot can be considered nowadays as a metadatabase as its entries contain information from diverse sources. It was created with two goals, constitute a non-redundant comprehensive protein sequence database and enrich that database with annotation of those proteins. Annotations include, but it is not limited to: protein and gene families, function and structure-function available data, interactions with other proteins or cofactor, localization, patterns of expression, variants… Thus, it aims to join the goals of both primary and secondary DDBBs.\nThe central hub of Uniprot databases is Uniprot Knowledgebase. It is a collection of functional information on proteins, with accurate, consistent, and rich annotation. The UniProtKB consists of two internal databases: a section containing manually-annotated records with information extracted from literature, community suggestions, and curator-evaluated computational analysis, and a section with computationally analyzed records. For the sake of continuity and name recognition, the two sections are referred to as “UniProtKB/Swiss-Prot” (reviewed, manually annotated) and “UniProtKB/TrEMBL” (unreviewed, automatically annotated), respectively.\nBesides cross-references to structural information, in the last years, UniprotKB has also incorporated structural data from Alphafold database (created by DeepMind and EBI), see “State-of-the-art protein modeling with Deep Learning-based methods” module.\nSequences with different detail of annotation can be found in two overlapping and complementary databases in Uniprot: Uniparc and Uniref. Briefly, UniParc (UniProt Archive) is a comprehensive and non-redundant database that contains most of the publicly available protein sequences in the world. UniParc avoided redundancy by storing each unique sequence only once and giving it a stable and unique identifier (UPI) making it possible to identify the same protein from different source databases. A UPI is never removed, changed, or reassigned. On the other hand, UniRef (UniProt Reference Clusters) provide clustered sets of sequences from the UniprotKB (and selected UniParc records) in order to obtain complete coverage of the sequence space at several resolutions while hiding redundant sequences (but not their descriptions) from view. The UniRef100 database combines identical sequences into a single UniRef entry, displaying the sequence of a representative protein, the accession numbers of all the merged entries, and links to the corresponding. UniRef90 is built by clustering UniRef100 sequences using the MMseqs2 algorithm (Steinegger and Söding 2018) such that each cluster is composed of sequences that have at least 90% sequence identity and 80% overlap with the longest sequence (a.k.a. seed sequence ) of the cluster. Similarly, UniRef50 is built by clustering UniRef90 seed sequences that have at least 50% sequence identity to and 80% overlap with the longest sequence in the cluster. UniParc and Uniref contain only protein sequences. All other information about the protein must be retrieved from the source databases using the database cross-references.\n\n\nPfam\nPfam is a protein database that aims to classify sequences by their evolutionary relationships. It was founded in 1995 and it has been very useful for functional annotation of genomic data. Pfam’s website (http://pfam.xfam.org/) was closed by the end of 2022. However, Pfam database was not discontinued, but integrated into the InterPro site (see the Xfam Blog entry).\nPfam uses HMM profiles (we will discuss HMMs in the Homology Modeling module) to classify proteins into families, which are grouped into clans. Check out the EBI course about using Pfam: https://www.ebi.ac.uk/training/online/courses/pfam-creating-protein-families/\nThe current release (35.0) contains 19,632 entries (families and clans). Pfam was designed as a database that should be often updated in the fast-forward genomic era. To this aim, they use two alignment types. Each Pfam family has a seed alignment that contains a representative set of sequences for the entry. A profile hidden Markov model (HMM) is automatically built from the seed alignment and searched against a sequence database called pfamseq using the HMMER3 software (http://hmmer.org/). All sequence regions that satisfy a family-specific curated threshold, also known as the gathering threshold, are aligned to the profile HMM to create the full alignment (Mistry et al. 2020).\nIn addition to the HMM-based Pfam entries (Pfam-A), the Pfam profiles are used to provide a set of unannotated, computationally generated multiple sequence alignments called Pfam-B. However, in the last Pfam versions, the Pfam-B alignments are presently only released on the Pfam FTP site.\nPfam has also been used in the creation of other resources such as Rfam (RNA families) and Dfam (transposable DNA elements).\n\n\nInterPro\nInterPro aims to be a functional secondary database, by classifying proteins into families, domains, and important sites. To classify proteins in this way, InterPro uses predictive models, known as signatures, provided by several different databases (up to 13) that make up the InterPro consortium. InterPro combines those different signatures representing equivalent families, domains, or sites, and provides additional information such as descriptions, literature references, and Gene Ontology (GO) terms, to produce a comprehensive resource for protein classification (see Blum et al. (2021)).\nInterPro database is updated every 2 months and it is very useful for annotation of ORFans or divergent proteins. In the last years, it has integrated more resources, including Pfam, as well as structural data and predictions, giving rise to a very handy resource for multiple purposes in protein science (Paysan-Lafosse et al. 2023).\n\n\n\n\n\n\nNote\n\n\n\nInterpro was created as a sequence DDBB, but it is currently in between. I’d rather say that it is more a “meta-database” containing sequence and structure information."
  },
  {
    "objectID": "ddbb.html#structure-databases",
    "href": "ddbb.html#structure-databases",
    "title": "Protein Databases",
    "section": "Structure databases",
    "text": "Structure databases\n\nRCSB-PDB\nNow www.rcsb.org\n\n\nSCOP\nThe Structural Classification of Proteins (SCOP, http://scop.mrc-lmb.cam.ac.uk) database is a classification of protein domains organised according to their evolutionary and structural relationships (Andreeva et al. 2020).\n\n\nCATH\nCATH (www.cathdb.info) is a free, publicly available resource that identifies protein domains within proteins from the Protein Data Bank and classifies them into evolutionary related groups according to sequence, structure, and function information. It assumes that evolutionary related proteins with similar folds often exhibit similar functions (this only could be demonstrated if we find intermediates). CATH uses a hierarchical classification scheme where the units compared and classified are structural domains. Domains, defined here as globular structural domains capable of semi-independent folding, are extracted from experimentally determined protein structures available in the PDB database.\nCATH uses a combination of several structure-based (SSAP, CATHEDRAL) and sequence-based (Needleman-Wunsch-based sequence alignments, jackhmmer, Profile Comparer, and HHsearch) algorithms to assess the similarity of domains to each other and to identify protein homologues (Sillitoe et al. 2021).\nCATH has a sister resource, Gene3D, that adds in additional protein domain sequences with no known structure, which brings the current total number of domains in CATH-Gene3D up to 95 million.\nCATH database is updated quite regularly through daily snapshots (CATH-B), but a full release with more tools, named CATH+ is released every 12-months. CATH-plus contains functional families (CATH-FunFams), structural clusters and other tools (Sillitoe et al. 2021)."
  },
  {
    "objectID": "intro.html#warning-for-current-and-future-structural-biologists",
    "href": "intro.html#warning-for-current-and-future-structural-biologists",
    "title": "Introduction",
    "section": "Warning for current and future structural biologists",
    "text": "Warning for current and future structural biologists\n\n\n\n\n\nFigure 1: Ceci n’est pas une proteine. Source: https://swissmodel.expasy.org/static/course/files/PartIII_quality_assesment.pdf\n\n\nThe surrealist Belgian painter René Magritte created a collection of surrealistic paintings entitled La trahison des images (1928–1929). The most renowned of those paintings show a smoking pipe and the following caption underneath: “Ceci n’est pas une pipe” (This is not a pipe). Yes, indeed! It is actually the painting of a pipe.\nSimilarly, a picture of a protein, or a PDB file with the coordinates of a protein structure, is not a protein. It is a representation of ONE structure. Even experimentally determined structures have two main limitations that we should always keep in mind: (1) they are a fixed structure whereas proteins in vivo are flexible and dynamic and (2) they are subjected to experimental error and they often contain regions of low reliability. Moreover, even experimentally obtained macromolecular structures are to some degree models, with a variable ratio between experimental data and computational prediction to match the experimental data (X-ray diffraction, cryo-EM density maps, NMR, SAXS, FRET…) with previously known structures or prediction models. Obviously, that does not mean that protein structures are useless, they can be very useful, but we must be aware of the limitations as well as the applications."
  },
  {
    "objectID": "ddbb.html#graphical-summary",
    "href": "ddbb.html#graphical-summary",
    "title": "Protein Databases",
    "section": "Graphical summary",
    "text": "Graphical summary\n\n\n\nFigure 3: Main features of protein databases (updated in 2020)"
  },
  {
    "objectID": "ddbb.html#strDDBB",
    "href": "ddbb.html#strDDBB",
    "title": "Protein Databases",
    "section": "Structure databases",
    "text": "Structure databases\n\nRCSB-PDB\nThe Protein Data Bank (PDB, www.rcsb.org) database is the major macromolecule structural primary database (Burley et al. 2020). It contains mostly protein structures, but also spans nucleic acids and nucleoprotein complexes. PDB turned 50 in 2021 and you can see a detailed overview of its history in the RCSB-PDB site.\nBriefly, the PDB was established in 1971 at Brookhaven National Laboratory with only 7 structures. Then, the Research Collaboratory for Structural Bioinformatics (RCSB), formed by Rutgers, UCSD/SDSC, and CARB/NIST, became responsible for the management of the PDB in 1998 in response to an RFP and a lengthy review process. In 2003, the Worldwide Protein Data Bank (wwPDB) was formed to maintain a single PDB archive of macromolecular structural data that is freely and publicly available to the global community. It consists of organizations that act as deposition, data processing and distribution centers for PDB data.\nPDB structures are largely obtained by X-ray crystallography, but it accepts derived from EM and RMN data since 1989 and 1991, respectively. Indeed, the BMRB (Biological Magnetic Resonance Bank) has partnered with the PDB since 2006 and the EMBD (Electron Microscopy Data Bank) since 2021. Furthermore, starting September 2022, the PDB also contains computed models from the Alphafold database (which we will discuss later in this course) and RoseTTAFold-ModelArchive. Thus, the PDB database is the major hub that centralizes biological structures nowadays.\nPDB database has four mirrors and websites (RCSB, Europe, BMRB, and Japan) with mainly overlapping information, although they have some specialization. The RCSB PDB site has also an educational section (PDB-101) with very useful info and resources for teaching and learning structural biology and the work with PDB structures.\nThe PDB entries contain all the information about the structure, spanning from the protein sequence and source to the experiment details, as well as the structure assessment (see Structural quality assurance section) and visualization. You can download all this information and the structure coordinates in diverse file formats.\n\n\nSCOP\nThe Structural Classification of Proteins (SCOP, http://scop.mrc-lmb.cam.ac.uk) database is a classification of protein domains organized according to their evolutionary and structural relationships in hierarchical categories. The main unit is the family that groups related proteins with clear evidence for their evolutionary origin while the superfamily brings together more distantly related protein domains. Further, superfamilies are grouped into distinct folds on the basis of the global structural features shared by the majority of their members. Domain definitions are provided for the two main levels of the SCOP classification, family and superfamily, and the domain boundaries for each of these can coincide or differ (Andreeva et al. 2020).\nFor each group, a representative is selected based on its sequence (UniProtKB) and structure (PDB) and used for SCOP classification. Thus, the SCOP domain boundaries are assigned to both, the PDB and UniProtKB entry.\n\n\nCATH\nCATH (www.cathdb.info) is a free, publicly available resource that identifies protein domains within proteins from the Protein Data Bank and classifies them into evolutionary-related groups according to sequence, structure, and function information. It assumes that related proteins which fold alike often exhibit similar functions (this only could be demonstrated if we find intermediates). CATH uses a hierarchical classification scheme where the units compared and classified are structural domains. Domains, defined here as globular structural domains capable of semi-independent folding, are extracted from experimentally determined protein structures available in the PDB database. The domains are classified into the following hierarchical levels that compose the CATH name: Class (C), Architecture (A), Topology (T), and Homologous superfamilies (H).\nCATH uses a combination of several structure-based (SSAP, CATHEDRAL) and sequence-based (Needleman-Wunsch-based sequence alignments, Jackhmmer, Profile Comparer, and HHsearch) algorithms to assess the similarity of domains to each other and to identify protein homologues (Sillitoe et al. 2021).\nCATH has a sister resource, Gene3D, that adds in additional protein domain sequences with no known structure, which brings the current total number of domains in CATH-Gene3D up to 95 million.\nCATH database is updated quite regularly through daily snapshots (CATH-B), but a full release with more tools, named CATH+ is released every 12 months. CATH-plus contains functional families (CATH-FunFams), structural clusters, and other tools (Sillitoe et al. 2021)."
  },
  {
    "objectID": "pdb.html#x-ray-crystallography-or-single-crystal-x-ray-diffraction",
    "href": "pdb.html#x-ray-crystallography-or-single-crystal-x-ray-diffraction",
    "title": "Protein Structures",
    "section": "2.1 X-ray crystallography or single crystal X-ray diffraction",
    "text": "2.1 X-ray crystallography or single crystal X-ray diffraction\nX-ray crystallography, or single-crystal X-ray diffraction, is a method for determining the atomic structure of molecules in regular, crystalline structures. It requires the generation of a crystal of the molecule of interest, which is then mounted on a goniometer and illuminated or irradiated with a focused X-rays beam. The diffraction pattern of the X-rays on the other side of the crystal allows determination of the positions of the atoms, as well as their chemical bonds, crystallographic disorder, and various other information. However, the connection between the diffraction pattern and the electron density is not trivial and requires some complex maths, the so-called Fourier transforms.\n\n\n\n\n\n\nFigure 2: Schematic workflow of X-ray crystallography. From Creative Structure website.\n\n\n\nX-ray diffraction is a powerful method that allows obtaining high-resolution atomic-level structures of soluble or membrane proteins, either as apoenzymes or as holoenzymes bound to a substrate, cofactor or drugs. However, the sample must be crystallizable (i.e., homogeneous), which requires a substantial amount of very pure protein. Another disadvantage of X-ray structures is that, as mentioned earlier, you only get one (or very few) static forms of the protein and the location of the hydrogen atoms cannot be determined by conventional diffraction methods —the fact that they have only one electron makes it very difficult to detect them accurately with X-rays, since X-rays scatter at the electron density. They can be predicted, but that still hinders some chemical analyzes.",
    "crumbs": [
      "Background",
      "Protein Structures"
    ]
  },
  {
    "objectID": "pdb.html#nuclear-magnetic-resonance",
    "href": "pdb.html#nuclear-magnetic-resonance",
    "title": "Protein Structures",
    "section": "2.2 Nuclear Magnetic Resonance",
    "text": "2.2 Nuclear Magnetic Resonance\nAll atomic nuclei are charged, fast spinning particles, which gave rise to resonance frequencies that are different for each atom. Therefore, if we apply a magnetic field we can obtain an electromagnetic signal with a characteristic frequency of the magnetic field at the nucleus. This is the basis of nuclear magnetic resonance (NMR).\nWe should also remember that the motion of the nucleus is not isolated and it interacts both intra- and intermolecularly with the surrounding atoms. Nuclear magnetic resonance spectroscopy can therefore provide structural information about a particular molecule. Taking a protein as an example, its secondary structures, such as α-helix, β-sheet, or turn, reflect the different arrangement of the main chain atoms of protein molecules in three dimensions. The distances between the atomic nuclei in the different secondary structures, the interaction between the nuclei, and the dynamic properties of the polypeptide segments all directly reflect the three-dimensional structure of proteins. These nuclear features all contribute to the spectroscopic behavior of the analyzed sample and thus provide characteristic NMR signals. Interpretation of these signals by computational methods leads to deciphering the three-dimensional structure.\n\n\n\n\n\n\nFigure 3: Basis of nuclear magnetic resonance. From Creative Structure website.\n\n\n\nThe most important feature of the NMR method is that the three-dimensional structure of macromolecules in their natural state can be measured directly in solution, and NMR can provide unique information about the dynamics and intermolecular interactions. The resolution of the three-dimensional structure of macromolecules can extend to the subnanometer range. However, the NMR spectrum of large molecular weight biomolecules is very complicated and difficult to interpret, limiting the application of NMR in analyzing large biomolecules, often below 20-30 kDa (see Figure 4). In addition, this technique requires relatively large amounts of pure samples (on the order of several mg) to achieve a reasonable signal-to-noise ratio level.\n\n\n\n\n\n\nFigure 4: Coverage of molecular weight by structural technique. From .",
    "crumbs": [
      "Background",
      "Protein Structures"
    ]
  },
  {
    "objectID": "pdb.html#electron-cryomicroscopy",
    "href": "pdb.html#electron-cryomicroscopy",
    "title": "Protein Structures",
    "section": "2.3 Electron cryomicroscopy",
    "text": "2.3 Electron cryomicroscopy\nThe essential mechanism of Cryo-EM is the same of any electron microscopy method, i. e., electron scattering. Samples are prepared through cryopreservation prior to analysis. The, a source electrons is used as a light source to measure the sample. After the electron beam passes through the sample, a complex lens system converts the scattered signal into a magnified image recorded on the detector. A key subsequent step is signal processing, that transform thousands of images of the particles in any orientation into a three-dimensional structure of the sample.\n\n\n\n\n\n\nFigure 5: The process of Cryo-EM single particle analysis technique. From Creative Structure website.\n\n\n\nThe use of electron microscopy methods for structural biology was traditionally limited to very large macromolecular complexes, like viral capsids, and only recently it could be used for smaller particles (see Figure 4). The number of protein structures being determined by cryo-electron microscopy is growing at an explosive rate in the last 5-10 years. This is thanks to several technical improvements in the technique, spanning sample preparation, analysis and processing that allow obtaining pictures at the atomic level (Callaway 2020). This advances were acknowledged by the 2017 Nobel Prize in Chemistry to Jacques Dubochet, Joachim Frank and Richard Henderson.\n\n\n\n\n\n\nFigure 6: Cryo-electron microscopy revolution. From Creative Structure website.\n\n\n\n\nTip\nCheck the already classic article by Egelman (2016) for more a detailed info. And here for a great outreaching article after the Nobel Prize.\n\nCryoEM is widely use nowadays because, particularly for large molecular complexes or viral particles. Structures can be generated quickly, as it does not require a high amount of protein and it can generate good data even in the presence of impurities. However, new generation microscopes are only affordable by large institutions and small particles can have a high level of noise. Moreover, processing a large amount of images can be limiting to obtain high-quality structures.",
    "crumbs": [
      "Background",
      "Protein Structures"
    ]
  },
  {
    "objectID": "pdb.html#protein-structure-file-formats",
    "href": "pdb.html#protein-structure-file-formats",
    "title": "Protein Structures",
    "section": "4.1 Protein structure file formats",
    "text": "4.1 Protein structure file formats\nExperimental structural data from different methods are stored in different file formats. For instance, raw crystallographic data are usually stored as *.ccp4 files, but Cryo-EM or X-ray density maps can be stored in *.mrc or *.mtz files. Other complex file formats, such as the Extensible Markup Language *.xml, provide a framework for structure complex information and documents like protein structures.\nAlong with the establishment of the Protein Data Bank, a simple and standardized format was developed. The Brookhaven or PDB format consists of line records in a fixed format describing atomic coordinates, chemical and biochemical features, experimental details of the structure determination, and some structural features such as secondary structure assignments, hydrogen bonding, or active sites. The current version is named PDBx/mmCIF) also incorporates the expanded crystallographic information file format (mmCIF), which allows the representation of large structures, complex chemistry, and new and hybrid experimental methods. Thus a *.pdb and *.cif files can be considered as identical files.\n\n\n\n\n\n\nPDB-101\n\n\n\n\n\nCheck PDB-101 course about PDBx/mmCIF format at PDB RCSB site here.\n\n\n\n\n\n\n\n\n\nFigure 8: Coordinates in the PDB file (6KI3)\n\n\n\n\nOccupancy and B-factor\nExcept for the repetition of the atom type in the rightmost column, the last columns in the PDB file are the Occupancy and the temperature factor or the B-factor.\nMacromolecular crystals consist of many individual molecules packed in a symmetrical arrangement. In some crystals there are slight differences between the individual molecules. For instance, a sidechain on the surface may wag back and forth between several conformations, or a substrate may bind in two orientations at an active site, or a metal ion may be detected as bound to only a few of the molecules. When researchers build the atomic model of these portions, they can use the occupancy to estimate the amount of each conformation observed in the crystal. Therefore, by definition, the sum of occupancy values for each atom must be 1. Usually, we see a single record for an atom, with an occupancy value of 1, indicating that the atom is found in all of the molecules in the same place in the crystal. However, if a metal ion binds to only half of the molecules in the crystal, the researcher sees a faint image of the ion in the electron density map and can assign an occupancy of 0.5 for this atom in the PDB structure file. For each atom, two (or more) atom records are included with occupancies such as 0.5 and 0.5, or 0.4 and 0.6, or other fractions of occupancies that sum to a total of 1.\nOn the other hand, the temperature value or B-factor is a measure of our confidence in the location of individual atoms, as described above (Section 3). If you find an atom with a high temperature factor on the surface of a protein, keep in mind that this atom is likely to be moving around a lot and that the coordinates given in the PDB file are only a possible snapshot of its location. Thus, an atom dataset with an occupancy &lt; 1 may have a low B-factor if that position is safe.\nAs you can imagine, this column is also used by computationally derived models to indicate a confidence value that can be parsed for diverse purposes, including structure coloring.",
    "crumbs": [
      "Background",
      "Protein Structures"
    ]
  },
  {
    "objectID": "pdb.html#pymol",
    "href": "pdb.html#pymol",
    "title": "Protein structures",
    "section": "PyMOL",
    "text": "PyMOL\nPyMOL is a very powerful molecular visualization system written originally by Warren DeLano. It was released in 2000 and soon became very popular. It’s currently commercialized under License by Schrödinger but a free license for teaching can be requested. Also, source code is available on GitHub that can be installed on Linux or MAC. More info on Wikipedia.\nPyMOL allows working with different structures representation, but also with raw experimental data in different formats.\nPyMOL is written in Python and can be used with interactive menus and also with command line. There are a lot of resources that can help you with PyMOL, like a Documentation Reference Wiki or a community-supported PyMOLWiki. Moreover, it allows the implementation of new functionalities as plugins, like PyMod or DockingPie, among others. Finally, as any Python-based program, it can be used within Jupyter notebooks (see https://www.computer.org/csdl/magazine/cs/2021/02/09354947/1rgCkrAJCko)."
  },
  {
    "objectID": "pdb.html#a-10-steps-self-guided-practice",
    "href": "pdb.html#a-10-steps-self-guided-practice",
    "title": "Protein Structures",
    "section": "5.1 A 10-steps self-guided practice",
    "text": "5.1 A 10-steps self-guided practice\nThis is a Evernote note that you can consult online and also copy into your Evenote account if you wish."
  },
  {
    "objectID": "pdb.html#pymol-challenge",
    "href": "pdb.html#pymol-challenge",
    "title": "Protein Structures",
    "section": "5.2 PyMOL Challenge",
    "text": "5.2 PyMOL Challenge\nMake a ready-to-publish picture of your favorite protein. As a suggestion, you can reproduce the top panels in the Figure 1B of Gao et al. (2020), but any structure involving more than one domain and/or with a substrate/cofactor molecule can be a good challenge."
  },
  {
    "objectID": "pdb.html#biological-macromolecules-display-applications",
    "href": "pdb.html#biological-macromolecules-display-applications",
    "title": "Protein Structures",
    "section": "4.2 Biological macromolecules display applications",
    "text": "4.2 Biological macromolecules display applications\n\nPyMOL\nPyMOL is a very powerful molecular visualization system written originally by Warren DeLano. It was released in 2000 and soon became very popular. It’s currently commercialized under License by Schrödinger but a free license for teaching can be requested. Also, open source code is available on GitHub that can be installed on Linux or MAC. More info on Wikipedia. You can also check this quick Reference guide\nPyMOL allows working with different structures representation, but also with raw experimental data in different formats.\nPyMOL is written in Python and can be used with interactive menus and also with command line. There are a lot of resources that can help you with PyMOL, like a Documentation Reference Wiki or a community-supported PyMOLWiki. Moreover, it allows the implementation of new functionalities as plugins (Rosignoli and Paiardini 2022), like PyMod or DockingPie, among others. PyMod (Janson and Paiardini 2021) is designed to act as simple and intuitive interface between PyMOL and several bioinformatics tools (i.e., PSI-BLAST, Clustal Omega, HMMER, MUSCLE, CAMPO, PSIPRED, and MODELLER). Starting from the amino acid sequence of the target protein, PyMod is designed to carry out the main steps of the homology modeling process (that is, template searching, target-template sequence alignment and model building) in order to build a 3D atomic model of a target protein (or protein complex). The integration with PyMOL facilitates a detailed analysis of the modeling process.\nFinally, as any Python-based program, it can be used within Jupyter notebooks (see https://www.computer.org/csdl/magazine/cs/2021/02/09354947/1rgCkrAJCko).\n\n\nUCSF ChimeraX\nChimeraX (Pettersen et al. 2021) is a fully open source software, developed by the UCSF as a renovated version of the former Chimera software, with versions for Linux, MacOS, and Windows. It aims to be a comprehensive structural biology tool, but it is more widely known for its capacities for EM maps. As any other open source software, it has gained new and exciting capacities in the last years, like Virtual Reality capabilities or Alphafold2 modeling.\n\n\n\n\n\n\nNote\n\n\n\nThere is an excellent ChimeraX User Guide, with examples at the RBVI@UCSF site here.\n\n\n\n\nMolecular structures on your website: Mol* and others\nLiteMol Viewer is a powerful HTML5 web application for 3D visualization of molecules and other related data. It is used in a web browser, eliminating the need for external software and also allowing the integration with third-party sites as an embedded plugin. More information about LiteMol can be found on Sehnal et al. (2017), the wiki, or YouTube tutorials.\nThe same philosophy applies to other open-source viewers that were developed later and are now more widely used, like NGL Viewer and Mol* Sehnal et al. (2021), used in RCSB-PDB and PDBe sites for 3D visualization of structures. With Mol* you can save your work session in molj (without the actual structures) or molx (with embedded structures) formats, as in the Figure 8 above.\nFinally, for computational scientists, there are also many libraries that allow 3D molecules representation, like 3Dmol Javascript library and its Python wrapper Py3Dmol, which you can use in Colab, Jupyter, Quarto or any other Python notebook (see code examples here or here).\n\n\n\n\n\n\nMol* & Quarto\n\n\n\n\n\nMol* can be very easily integrated in other third party services and in your own website. For instance, it has a Quarto extension, which prompted me to use it on this site.\n\n\n\n\n\n\n\n\n\nA tribute to the pioneers\n\n\n\n\n\nOther applications that you may know, hear about or came into but are now discontinued are:\n\nSwissPDBViewer (aka DeepView), developed to work with SWISS-MODEL homology modeling app, is an application that provides a user-friendly interface allowing to analyze several proteins at the same time. It has currently fallen in disuse as the last version (4.1) is only a 32 bits application.\nRasMol and OpenRasMol were developed initially in 1992 and its last release was in 2009. It was a pioneer as a simple molecular display open-source application, but it is outdated nowadays.",
    "crumbs": [
      "Background",
      "Protein Structures"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Structural Bioinformatics 2022-23",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "pdb.html#global-parameters-in-experimentally-based-structures",
    "href": "pdb.html#global-parameters-in-experimentally-based-structures",
    "title": "Protein Structures",
    "section": "3.1 Global parameters in experimentally-based structures",
    "text": "3.1 Global parameters in experimentally-based structures\nThere are a number of different parameters that help us understand the quality and reliability of a structure. First, the resolution is a good indicator of the level of detail of the structure, as it can greatly affect affect how the experimental data are modeled.\n\n\n\n\n\n\nFigure 7: The effect of resolution on the quality of the electron density. The Tyr100 residue from concanavalin A as found in the indicated PDB structures at 3 Å, 2 Å and 1.2 Å. Reproduction of Figure 14.5 from Gu and Bourne (2009) rendered with Pymol (see concanavalin.pse and concanavalin.txt in the Repo for details about the picture display).\n\n\n\n    \n    \n     Embedded reproduction of the Figure 7 with Mol*, which allow you to explore the structures.\nAnother important parameter is the R-factor, which is the difference between the structure factors calculated from the model and those obtained from the experimental data. That is, the R-factor is the deviation between the calculated diffraction pattern of the model and the original experimental diffraction pattern. Typically, good structures with a resolution of 1-3 Å, have an R-factor of 0.2 (i.e., 20% of deviation). However, it should be noted that this factor is usually reduced after iterative refinement, which downplays its use as an indicator of reliability. A more reliable factor is the Rfree factor. This is less susceptible to manipulation during refinement, as it is based on only a small portion of the experimental data (5-10%) that is not used during the refinement phase.\nA more intuitive, but only qualitative, way to understand the precision of the coordinates of a given atom is the B-factor. The temperature value or B-factor correlates with the position errors, although its mathematical definition is more complex. Normal values for a B-factor are in the range of 14-30, while values above 30 usually indicate that the atom is in a flexible or disordered region, and atoms with a B-factor above 40 are often ruled out as too unreliable.\nThe root-mean-squared deviation (RMSD, see Structure alignment section) is a traditional estimator of the quality of NMR-solved structures. Regions with high RMSD values are those that are less defined by data. However, it should also be noted that this parameter can be also misleading, as it is highly dependent on the procedure used to generate and select the data that is submitted to the PDB. An experimentalist could reduce the RMSD by selecting the “best” few structures for deposition from a much larger draft. Note that the RMSD has many other applications, like comparing different structures or models from the same or related sequences.\nIn recent years, with the increase of quantity and quality of EM structures, new parameters have also been proposed. One of them, the Q-factor was recently introduced for validation of 3DEM/PDB structures. Briefly, the Q-factor score calculates the resolvability of atoms by measuring the similarity of the map values around each atom relative to a Gaussian-like function for a well resolved atom. A Q score of 1 means that the similarity is perfect, while a value close to 0 indicates low similarity. If the atom is not well placed in the map, a negative Q value can be given. Therefore, Q-factor values in the reports range from -1 to +1.",
    "crumbs": [
      "Background",
      "Protein Structures"
    ]
  },
  {
    "objectID": "pdb.html#stereochemical-parameters",
    "href": "pdb.html#stereochemical-parameters",
    "title": "Protein Structures",
    "section": "3.2 Stereochemical parameters",
    "text": "3.2 Stereochemical parameters\nSince all structural models contain some degree of error and some of the global modeling parameters may be controversial, we can analyze the geometry, stereochemistry, and other structural properties of the model to evaluate structural models. These parameters compare a given structure to what is already known about that type of molecule based on our knowledge from high-resolution structures. This means that the structures in the current structure space define what is “normal” in a protein structure. The advantage of these analyses and derived parameters is that they do not take into account the process that leads to the model, only the final product and its reliability. The main disadvantage is that the current structure space is focused on proteins with known function and of biomedical or biotechnological interest.\nOne of the most common and powerful methods for assessing the stereochemistry of a protein is the Ramachandran plot, which was defined in 1963 and is still in use.\nAnother widely used analysis (available for all PDB structures) is the side chain torsion angles, usually measured as Side chain outliers. As described in the Introduction, the amino acid side chains also have some preferred conformations. Like the Ramachandran plot, the plot of the χ1-χ2 torsion angles can indicate problems with a protein model if the angle values are outside of the high density values.\nBad contact or clashes indicate a poor model. It is obvious that two atoms cannot be in the same (or a very close) location. We can define this as a situation where two unbound atoms have a center-to-center distance smaller than the sum of their van der Walls radii.",
    "crumbs": [
      "Background",
      "Protein Structures"
    ]
  },
  {
    "objectID": "ddbb.html#classify-the-following-protein-structures-into-groups-and-subgroups",
    "href": "ddbb.html#classify-the-following-protein-structures-into-groups-and-subgroups",
    "title": "Protein Databases",
    "section": "Classify the following protein structures into “groups” and “subgroups”",
    "text": "Classify the following protein structures into “groups” and “subgroups”\nFocus only in structural databases (CATH, Scop2), but any given database can be helpful in a different way. Use generic terms, valid for any hierarchical classification, independent of the database(s) used.\n\n\n\nStructures\n\n\n\n\n2MNA\n\n\n2WB0\n\n\n1C0A\n\n\n1QUM\n\n\n5ZHZ\n\n\n5CFE\n\n\n1DE9\n\n\n6WCD\n\n\n1AKO\n\n\n6KHY"
  },
  {
    "objectID": "ddbb.html#briefly-answer-these-questions",
    "href": "ddbb.html#briefly-answer-these-questions",
    "title": "Protein Databases",
    "section": "3.2 Briefly answer these questions:",
    "text": "3.2 Briefly answer these questions:\n\n3.2.1 a. Can you suggest the structural and evolutionary relationship between them?\n\n\n3.2.2 b. Which of the structures is more difficult to group"
  },
  {
    "objectID": "ddbb.html#answer-these-questions",
    "href": "ddbb.html#answer-these-questions",
    "title": "Protein Databases",
    "section": "Answer these questions",
    "text": "Answer these questions\n\na. Can you suggest the structural and evolutionary relationship between them?\n\n\nb. Which of the structures is more difficult to group\n\n\nc. Which are the pros/cons of each database?\nAnswer briefly."
  },
  {
    "objectID": "intro.html#sec-rama",
    "href": "intro.html#sec-rama",
    "title": "Introduction",
    "section": "2.1 Ramachandran Plot",
    "text": "2.1 Ramachandran Plot\nAs you likely deduced already, many combinations of φ and ψ angles are prohibited due to the principle of steric exclusion, which dictates that two atoms cannot occupy the same space simultaneously. This concept was initially demonstrated by Gopalasamudram Ramachandran, who developed a plot to visualize the permissible angle values, known as the Ramachandran plot. This plot can display the angles of a specific amino acid, all amino acids in a single protein, or even across many proteins. Analysis of φ and ψ angles in known proteins reveals that approximately three-quarters of all possible φ, ψ combinations are not allowed (Figure 9) that correspond with common secondary structure motifs (?@fig-rama).\n\n\n\n\n\n\nFigure 9: General Ramachandran plot. The density of points reflects how likely is each angle combination, defining the core (red line) and tolerance (orange) regions.\n\n\n\n\n\n\n\n\n\nFigure 10: Definition of secondary structure alternatives by their combination of phi, psi angles.\n\n\n\nFunctionally relevant residues are more likely than others to have torsion angles that plot to the allowed but disfavored regions of a Ramachandran plot. The specific geometry of these functionally relevant residues, while somewhat energetically unfavorable, may be important for the protein’s function, catalytic or otherwise. Such conformations need to be stabilized by the protein using H-bonds, steric packing, or other means, and should very seldom occur for highly solvent-exposed residues.\n\n\n\n\n\n\nFigure 11: Ramachandran plots for glycine (left) and proline (right) Inner contour encloses 98% and 99.9% of Top structures data, indicating the favored and allowed regions, respectively .",
    "crumbs": [
      "Background",
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#protein-folds-domains-and-motifs",
    "href": "intro.html#protein-folds-domains-and-motifs",
    "title": "Introduction",
    "section": "2.2 Protein folds, domains and motifs",
    "text": "2.2 Protein folds, domains and motifs\nThe global three dimensional tertiary structure of a protein is commonly referred as its fold. Within the overall protein fold, we can recognize distinct domains and motifs. Domains are compact sections of the protein that represent structurally and (usually) functionally independent regions. That means that a domain maintain its main features, even if separated from the overall protein. On the other hand, motifs are small substructures that are not necessarily independent and consist of only a few secondary structure stretches. Indeed, motifs can be also referred as super-secondary structure.\nThe diversity of protein folds, domains and motifs, and combination of those, can be used for classification of protein structures hierarchically, as in many other fields of biology. The first classification was proposed in the 70’s and consisted of four groups of folds, as shown in the figure below. All α proteins are based almost entirely on an α-helical structure, and all β-structure are based on β-sheets. α/β structure is based on as mixture of α-helices and β-sheet, often organized as parallel β-strands connected by α-helices. On the other hand, α+β structures consist of discrete α-helix and β-sheet motifs that are not interwoven (as they are in α/β proteins). Finally, small proteins span polypeptides with no or little secondary structures.\n\n\n\n\n\n\nFigure 12: The four structural protein classes in the classification by Chlothia & Levitt. Modified from Gu and Bourne (2009) using 1I2T, 1K76, 1H75 and 1EM7 structures.",
    "crumbs": [
      "Background",
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#hands-on-playing-with-secondary-structures",
    "href": "intro.html#hands-on-playing-with-secondary-structures",
    "title": "Introduction",
    "section": "2.4 Hands on: Playing with secondary structures",
    "text": "2.4 Hands on: Playing with secondary structures\n\n\n\n\n\n\n\nGroups\n\n\n\nRemember to work on groups as assigned. Groups should be the same for all the course exercises.\n\n\nThere are a few online alternatives to model any peptide sequence and quickly see the effect of amino acid composition in the secondary structure. One of the best-known is Foldit (www.fold.it, Miller et al. (2020)), a gaming platform for biochemistry and structural biology teaching. It is a highly recommended alternative for most courses related to protein structure.\nIn this course we are going to try a more recent proposal, twitted by Sergey Ovchinnikov:\n\n\n;document.getElementById(\"tweet-32591\").innerHTML = tweet[\"html\"];\n\n\n\n\n\n\nFigure 13: Basic protein amino acids stats for protein design with ColabFold Single\n\n\n\nThis is based on ColabFold (see https://github.com/sokrypton/ColabFold and Mirdita et al. (2022)), an Alphafold2 (see Jumper et al. (2021)) free notebook in Google Colab notebook. All you need is a Google account and the cheatsheet in Figure 13.\nNow go to ColabFold Single: https://colab.research.google.com/github/sokrypton/af_backprop/blob/beta/examples/AlphaFold_single.ipynb\nConstruct some small proteins and compare the output. Use 6 recycle steps to obtain diverse structures and then click in the “Animate trajectories” chunk. Note that the first model will take 2-4 min, but the others will be faster. I provide here some interesting examples (IUPAC one-letter amino acid code):\n\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\nPVAVEARENGRLAVRVEGAIAVLIRENGRLVVRVEGG\nPELEKHREELGEFLKKETGIAVEIRENGRLEVRVEGYTDVKIEGGTERLKRFLEEL\nACTWEGNKLTCA\n\n1. Answer the following questions:\n- Why is a poly-K more stable (dark blue) than a poly-A?\n\n- Could you predict the structure of a poly-V or a poly-G?\n\n- What would happen if you introduce a K5W in the structure number 2? and in the 4?\n\n\n2. Now, try to create peptides with a custom motif, such as:\n\n- Two helices.\n- A four-strands beta-sheet.\n- Alpha-beta-beta-alpha.",
    "crumbs": [
      "Background",
      "Introduction"
    ]
  },
  {
    "objectID": "ai.html#the-recent-history-of-protein-structure-modeling-telling-by-a-contest-casp",
    "href": "ai.html#the-recent-history-of-protein-structure-modeling-telling-by-a-contest-casp",
    "title": "State-of-the-art protein modeling with Deep Learning-based methods",
    "section": "The recent history of protein structure modeling telling by a contest (CASP)",
    "text": "The recent history of protein structure modeling telling by a contest (CASP)\nEvery two years since 1994, structural bioinformatics groups carry out a worldwide experiment, predicting a set of unknown protein structures in a controlled, blind-test-like competition and comparing their output with the experimentally obtained structure. This is the CASP or Critical assessment of Protein Structure Prediction.\n\n\n\nComparative z-core of CASP13 participants. The score is based in the GDT_TS (Global distance test).\n\n\nThe best research groups in the field test their new methods and protocols in CASP. However, in CASP13 (2018) an AI company called Deepmind (Google Subsidiary) entered in the scene. Their method, named Alphafold (Senior et al. 2020) clearly won CASP13. Alphafold implemented some improvements in a few recently used approaches, creating a new whole pipeline. Basically, instead of create contact maps from the alignment to then fold the structure, they used a MRF unit (Markov Random Field) to extract in advance the main features of sequence and the MSA and process all of that info into a multilayer NN (called ResNet) that provides the distant map and other information. Then, Alphafold uses all the possibly obtained information to create the structure and then improve it by energy minimization and substitution of portions with a selected DB of protein fragments.\n\n\n\nWorkflow of the first Alphafold method presented in CASP13. MSA stands for multiple sequence alignment; PSSM indicates Position-specific-scoring matrix and MRF stands for Markov Random Field (or Potts model). From the Sergei Ovchinnikov and Martin Steinegger presentation of Alphafold2 to the Boston Protein Design Group (link below)\n\n\nAfter Alphafold, similar methods were also developed and made available to the general public, like the trRosetta from Baker lab (Yang et al. 2020), available in the Robetta server. This led to some controversy (mostly on Twitter) about the open access to the CASP software and later on DeepMind publishes all the code on GitHub."
  },
  {
    "objectID": "pdb.html#part-a-a-10-steps-self-guided-practice",
    "href": "pdb.html#part-a-a-10-steps-self-guided-practice",
    "title": "Protein Structures",
    "section": "5.1 PART A: A 10-steps self-guided practice",
    "text": "5.1 PART A: A 10-steps self-guided practice\nThis is a Evernote note that you can consult online and also copy into your Evenote account if you wish.",
    "crumbs": [
      "Background",
      "Protein Structures"
    ]
  },
  {
    "objectID": "pdb.html#part-b-pymol-challenge",
    "href": "pdb.html#part-b-pymol-challenge",
    "title": "Protein Structures",
    "section": "5.2 PART B: PyMOL Challenge",
    "text": "5.2 PART B: PyMOL Challenge\nMake a ready-to-publish picture of your favorite protein. As a suggestion, you can reproduce the top panels in the Figure 1B of Gao et al. (2020), but any structure involving more than one domain and/or with a substrate/cofactor molecule can be a good challenge.",
    "crumbs": [
      "Background",
      "Protein Structures"
    ]
  },
  {
    "objectID": "advanced.html",
    "href": "advanced.html",
    "title": "Advanced homology modeling",
    "section": "",
    "text": "Although we do not intend to describe in detail the evolution of modeling methods, I briefly outline below the origin and transformation of advanced protocols that outperform the classical single-template homology modeling during the last three decades. This step-wise evolution of modeling methods is the origin of the revolution of Alphafold and related protocols, which we will discuss in the next section.\n\n\nAs mentioned earlier, the introduction of HMM-based profiles during the first decade of this century led to a great improvement in template detection and protein modeling in the twilight zone, i.e., proteins with only distant homologs (&lt;25-30% identity) in databases. In order to exploit the power of HMM searches, those methods naturally evolved into iterative threading methods, based on multitemplate model construction, implemented in I-TASSER (Roy, Kucukural, and Zhang 2010), Phyre2 (L. A. Kelley et al. 2015), and RosettaCM (Song et al. 2013), among others. These methods are usually referred to as Threading or Fold-recognition methods. Note that the classification of modeling methods is often blurry. The current version of SwissModel and the use of HHPred+Modeller already rely on HMM profiles for template identification and alignment; being thus strictly also fold-recognition methods.\nBoth terms can be often used interchangeably, although some authors see Fold-Recognition as any technique that uses structural information in addition to sequence information to identify remote homologies, while Threading would refer to a more complex process of modeling including remote homologies and also the modeling of pairwise amino acid interactions in the structure. Therefore, HHPRED is a fold-recognition method and its use along with Modeller, could be indeed considered threading.\n\n\n\nFigure 1: The idea behind fold-recognition is that instead of comparing sequences, we intend to compare structures. In the Frozen approximation (left), one residue is aligned with the template structure and then we evaluate the probability of the nearby residues in the query sequence to be in the same position than the equivalent in the template. On the other hand, Defrost methods use profiles to generate improved alignments that allow better starting points to the energy calculations during the iterative modeling steps. From Lawrence A. Kelley (2009).\n\n\nThe Iterative Threading ASSembly Refinement (I-TASSER) from Yang Zhang lab is one of the most widely used threading methods and servers. This method was was ranked as the No 1 server for protein structure prediction in the community-wide CASP7, CASP8, CASP9, CASP10, CASP11, CASP12, CASP13, and CASP14 experiments. I-TASSER first generates three-dimensional (3D) atomic models from multiple threading alignments and iterative structural assembly simulations that are iteratively selected and improved. The quality of the template alignments (and therefore the difficulty of modeling the targets) is judged based on the statistical significance of the best threading alignment, i.e., the Z-score, which is defined as the energy score in standard deviation units relative to the statistical mean of all alignments.\n\n\n\nFigure 2: Flowchart of I-TASSER protein structure modeling. From Rigden (2017).\n\n\nFirst, I-TASSER uses Psi-BLAST against curated databases to select sequence homologs and generate a sequence profile. That profile is used to predict the secondary structure and generate multiple fragmented models using several programs. The top template hits from each threading program are then selected for the following steps. In the second stage, continuous fragments in threading alignments are excised from the template structures and are used to assemble structural conformations of the sections that aligned well, with the unaligned regions (mainly loops/tails) built by ab initio modeling. The fragment assembly is performed using a modified replica-exchange Monte Carlo random simulation technique, which implements several replica simulations in parallel using different conditions that are periodically exchanged. Those simulations consider multiple parameters, including model statistics (stereochemical outliers, H-bond, hydrophobicity…), spatial restraints and amino acid pairwise contact predictions (see below). In each step, output models are clustered to select the representative ones for the next stage. A final refinement step includes rotamers modeling and filtering out steric clashes.\nOne interesting thing about I-TASSER is that it is integrated within a server with many other applications, including some of the tools that I-TASSER uses and other advanced methods based on I-TASSER, like I-TASSER-MTD for large, multidomain proteins or C-I-TASSER that implements a deep learning step, similar to Alphafold2 (see next section).\n\n\n\nFigure 3: RosettaCM Protocol. (A) Flowchart of the RosettaCM protocol. (B–D) RosettaCM conformational sampling. From Song et al. (2013).\n\n\nRosettaCM is an advanced homology modeling or threading algorithm by the Baker lab, implemented in Rosetta software and the Robetta webserver. RossetaCM provides accurate models by breaking up the sequence into fragments that are aligned to a set of selected templates, generating accurate models by a threading processes that uses different fragments from each of the templates. Additionally it uses minor ab initio folding to fill the residues that could not be assigned during the threading. Then, the model is closed by iterative optimization steps that include Monte Carlo sampling. Finally, an all-atom refinement towards a minimum of free energy (Song et al. 2013).\n\n\n\n\n\n\nPuzzling nomenclature: comparative, homology or ab initio modeling?\n\n\n\nDe novo or ab initio modeling used to mean modeling a protein without using a template. However, this strict definition is blurred in the 2000s (decade) by advanced methods that use fragments. Threading protocols such as RosettaCM and I-Tasser, among others, use fragments that may or may not come from homologous protein structures or not. Therefore, they cannot be classified as homology modeling, but they are sometimes referred to as comparative or hybrid methods."
  },
  {
    "objectID": "advanced.html#from-homology-modeling-to-threading",
    "href": "advanced.html#from-homology-modeling-to-threading",
    "title": "Advanced homology modeling",
    "section": "From homology modeling to threading",
    "text": "From homology modeling to threading\nAs mentioned earlier, the introduction of HMM-based profiles during the first decade of this century led to a great improvement in template detection and protein modeling in the twilight zone, i.e., proteins with only distant homologs (<25-30% identity) in databases. Current version of SwissModel and the use of HHPred+Modeller already rely on HMM profiles for template identification and alignment. In order to exploit the power of HMM searches, those methods naturally evolved into iterative threading methods, based on multitemplate model construction, implemented in I-TASSER (Roy, Kucukural, and Zhang 2010), Phyre2 (Kelley et al. 2015), and RosettaCM (Song et al. 2013), among others. These methods methods are usually referred as Threading or Fold-recognition methods. Both terms can be often used interchangeably, although some authors see threading as any technique that uses structural information in addition to sequence information to identify remote homologies, while threading would be a more complex process of modeling including remote homologies and also modeling of pairwise amino acid interactions in the structure. Therefore, although we have already used HHPred along with the use of HHPred to identify templates for a subsequent modeling, could be indeed considered as threading.\nThe iterative threading assembly refinement (I-TASSER) from Yang Zhang lab is one of the most widely used threading methods and servers. This method was was ranked as the No 1 server for protein structure prediction in the community-wide CASP7, CASP8, CASP9, CASP10, CASP11, CASP12, CASP13, and CASP14 experiments. I-TASSER first generates three-dimensional (3D) atomic models from multiple threading alignments and iterative structural assembly simulations that are iteratively selected and improved. The quality of the template alignments (and therefore the difficulty of modeling the targets) is judged based on the statistical significance of the best threading alignment, i.e., the Z-score, which is defined as the energy score in standard deviation units relative to the statistical mean of all alignments.\n\n\n\nFigure 1: Flowchart of I-TASSER protein structure modeling. From Rigden (2017).\n\n\nFirst, I-TASSER uses Psi-BLAST against a curated databases to select sequence homologs and generate a sequence profile. That profile is used to predict secondary structure and generate multiple fragmented models using several programs. The top template hits from each threading program are then selected for the following steps. In the second stage, continuous fragments in threading alignments are excised from the template structures, and are used to assemble structural conformations of the sections that aligned well, with the unaligned regions (mainly loops/tails) built by ab initio modeling. The fragment assembly is performed using a modified replica-exchange Monte Carlo random simulation technique, which implements several replica simulations in parallel using different conditions that are periodically exchanged. Those simulations consider multiple parameters, including model statistics (stereochemical outliers, H-bond, hydrophobicity…), spatial restrains and amino acid pairwise contact predicions (see below). In each step, output models are clustered to select the representative ones for the next stage. A final refinement step include rotamers modeling and filtering out steric clashes.\nOne interesting thing about I-TASSER is that it is integrated within a server with many other applications, including some of the tools that I-TASSER uses and other advanced methods based by I-TASSER, like I-TASSER-MTD for large, multidomain proteins or C-I-TASSER that implements a deep learning step, similar to Alphafold2 (see below).\n\n\n\n\n\nFigure 2: RosettaCM Protocol. (A) Flowchart of the RosettaCM protocol. (B–D) RosettaCM conformational sampling. From Song et al. (2013).\n\n\nRosettaCM is an advanced homology modeling or threading algorithm by the Baker lab, implemented in Rosetta software and the Robetta webserver. RosettaCM assemblies the model by recombining aligned segments in a set of selected templates and close the model by a minimization of the junctions between segments by fragments torsion and iterative optimization steps that include Monte Carlo sampling. Finally, an all-atom refinement towards a minimum of free energy (Song et al. 2013)."
  },
  {
    "objectID": "advanced.html#from-contact-maps-to-pairwise-high-res-feature-maps",
    "href": "advanced.html#from-contact-maps-to-pairwise-high-res-feature-maps",
    "title": "From advanced homology modeling to deep Learning-based methods",
    "section": "From contact maps to pairwise high-res feature maps",
    "text": "From contact maps to pairwise high-res feature maps\n\n\n\n\n\nFigure 3: Contact-based map of representative proteins. The map represents a matrix of amino acid positions in the protein sequences (on both, the X and Y axis); with contacts indicated as blue dots. When a number of consecutive residues in the sequence interact the dots form diagonal stretches. Maps obtained at http://cmweb.enzim.hu/\n\n\nDuring the last decade, the introduction of residue-residue contact or distance maps prediction based on sequence co-evolution and deep learning started a revolution in the field that crystallize with the arrival of Alphafold2 and RoseTTAfold as major breakthroughs with great repercussions in diverse fields. As shown in #fig-contact\n\n\n\nFigure 4: Schematic of how co-evolution methods extract information about protein structure from a multiple sequence alignment (MSA). Image modified from doi: 10.5281/zenodo.1405369, which in turn was modified from Marks et al. (2011).\n\n\nAs shown in the picture below, residue contact maps are a 2D matrix-like representation of the protein sequence in which each pair of interacting residues are indicated. An accurate information of protein’s residue–residue contacts is sufficient to elucidate the fold of a protein (Olmea and Valencia 1997); however predicting that map is not always easy. The introduction of evolutionary coupling analysis (ECA), i.e., extract the residue coevolution from MSAs (piture above) improved contact maps and allowed their implementation for protein folding in several methods, like PSICOV [Jones et al. (2012)] or Gremlin (Kamisetty, Ovchinnikov, and Baker 2013), among others. However, for proteins without many sequence homologs, the predicted contacts were of low quality and insufficient for accurate contact-assisted protein modeling.\n\n\n\nIllustration of column pair and precision submatrix grouping for advanced prediction of contact maps. In the example, Columns 5 and 14 in the first family are aligned to columns 5 and 11 in the second family, respectively, so column pair (5,14) in the first family and the pair (5,11) in the second family are assigned to the same group. Accordingly, the two precision submatrices will be asigned to the same group. From Ma et al. (2015).\n\n\nDeep learning is a sub-field of machine learning which is based on artificial neural networks (NN). Neural networks were introduced actually in the late 40’s and 50’s, but they reappeared in the 2000’s thanks to the increase of computational capacities and, more recently, the use of GPUs. Briefly, a NN uses multiple interconnected layers to transform multiple inputs (MSAs, high-resolution contact based maps…) into compound features that can be used to predict a complex output, like a 3D protein structure. As their name indicate, NNs attempt to simulate the behavior of the human brain that process large amounts of data and can be trained to “learn” from that data. Deep learning is based in the use of multiple layer-NN to optimize and refine for accuracy.\nIn this context, introduction of supervised machine learning methods that predict contacts from distant protein families, outperforming ECA methods by the use of multilayer neural networks [Jones et al. (2015), Ma et al. (2015)]. These methods allowed the use of the so-called high resolution contact maps, that contained not only contact information, but also probabilities, distances and angles.\n\n\n\n\n\nExample of high-resolution contact maps of 6MSP. From Yang et al. (2020)"
  },
  {
    "objectID": "advanced.html#the-recent-history-of-protein-structure-modeling-telling-by-a-contest-casp",
    "href": "advanced.html#the-recent-history-of-protein-structure-modeling-telling-by-a-contest-casp",
    "title": "Advanced homology modeling",
    "section": "The recent history of protein structure modeling telling by a contest (CASP)",
    "text": "The recent history of protein structure modeling telling by a contest (CASP)\nEvery two years since 1994, structural bioinformatics groups carry out a worldwide experiment, predicting a set of unknown protein structures in a controlled, blind-test-like competition and comparing their output with the experimentally obtained structure. This is the CASP or Critical assessment of Protein Structure Prediction.\n\n\n\nComparative z-core of CASP13 participants. The score is based in the GDT_TS (Global distance test).\n\n\nThe best research groups in the field test their new methods and protocols in CASP. However, in CASP13 (2018) an AI company called Deepmind (Google Subsidiary) entered in the scene. Their method, named Alphafold (Senior et al. 2020) clearly won CASP13. Alphafold implemented some improvements in a few recently used approaches, creating a new whole pipeline. Basically, instead of create contact maps from the alignment to then fold the structure, they used a MRF unit (Markov Random Field) to extract in advance the main features of sequence and the MSA and process all of that info into a multilayer NN (called ResNet) that provides the distant map and other information. Then, Alphafold uses all the possibly obtained information to create the structure and then improve it by energy minimization and substitution of portions with a selected DB of protein fragments.\n\n\n\nWorkflow of the first Alphafold method presented in CASP13. MSA stands for multiple sequence alignment; PSSM indicates Position-specific-scoring matrix and MRF stands for Markov Random Field (or Potts model). From the Sergei Ovchinnikov and Martin Steinegger presentation of Alphafold2 to the Boston Protein Design Group (slides and video in the [link below](#links)).\n\n\nAfter Alphafold, similar methods were also developed and made available to the general public, like the trRosetta from Baker lab (Yang et al. 2020), available in the Robetta server. This led to some controversy (mostly on Twitter) about the open access to the CASP software and later on DeepMind publishes all the code on GitHub."
  },
  {
    "objectID": "advanced.html#why-is-alphafold2-so-freaking-accurate",
    "href": "advanced.html#why-is-alphafold2-so-freaking-accurate",
    "title": "From advanced homology modeling to deep Learning-based methods",
    "section": "Why is Alphafold2 so freaking accurate?",
    "text": "Why is Alphafold2 so freaking accurate?\nThe philosophy behind Alphafold and related methods is treating the protein folding problem as a machine learning problem, kind of of image processing. In all these problems, the input to the Deep Learning model is a volume (3D tensor). In the case of computer vision, 2D images expand as a volume because of the RGB or HSV channels. Similarly, in the case of distance prediction, predicted 1D and 2D features are transformed and packed into 3D volume with many channels of inter-residue information (Pakhrin et al. 2021).\n\n\n\nFrom the perspective of Deep Learning method development, the problem of protein distogram or real-valued distance prediction (bottom row) is similar to the ‘depth prediction problem’ in computer vision. From Pakhrin et al. (2021).\n\n\nAlphafold2 can be explained as a pipeline with three interconected tasks (see picture below). First, it queries several databases of protein sequences and constructs an MSA that is used to select templates. In the second part of the diagram, AlphaFold 2 takes the multiple sequence alignment and the templates, and processes them in a transformer. This process has been referred by some authors as inter-residue interaction map-threading (Bhattacharya et al. 2021). The objective of this part is to extract layers of information to generate residue interaction maps. A better model of the MSA will improve the network’s characterization of the geometry, which simultaneously will help refine the model of the MSA. Importantly, in the AF2 Evoformer, this process is iterative and the information goes back and forth throughout the network. At every recycling step, the complexity of the map increases and thus, the model improves (the original model uses 3 cycles). As explained in the great post from Carlos Outerial at the OPIG site:\n\nThis is easier to understand as an example. Suppose that you look at the multiple sequence alignment and notice a correlation between a pair of amino acids. Let’s call them A and B. You hypothesize that A and B are close, and translate this assumption into your model of the structure. Subsequently, you examine said model and observe that, since A and B are close, there is a good chance that C and D should be close. This leads to another hypothesis, based on the structure, which can be confirmed by searching for correlations between C and D in the MSA. By repeating this several times, you can build a pretty good understanding of the structure.\n\nThe third part of the pipeline is the structure building module, which uses the information from the previous steps to construct a 3D model structure protein of the query sequence. This network will give you a single model, without any energy optimization step. Model building is based in a new concept of 3D structures generation, named IPA (Invariant Point Attention) and the use of a curated list of parametrised list of torsion angles to generate the side chains.\n\n\n\n\n\nOxford Proteins Informatics Group Blog, modified From\n\n\nLike for most of the previous methods Alphafold would give your better results with proteins with related structures known and with a lot of homologs in Uniref databases. However, comparing to nothing, it will likely give you (limited) useful results for the so-called “dark genome”. I work with phages and bacterial mobile elements, and sequencing that is often frustrating as more than 50% of the proteins have no homologs in the database. So you have a bunch of proteins of unknown function… However, as we do know that structure is more conserved than sequence, we may use the structure to find out the function of our dark proteins. There are a few resources for this, I’d suggest you to try FoldSeek [Kempen et al. (n.d.)] and Dali [Holm (2022)] servers. You can upload the PDB of your model and search for related structures in PDB and also in Alphafold database.\nAs mentioned above, Colabfold aims to make the process faster by using MMSeqs in the first block. Additionally, the number of recycling steps can also be adapted. Moreover, different Colabfold notebooks have been developed (and evolved) to allow some customization and other feature, like batch processing of multiple proteins avoiding recompilation and identification of protein-protein interactions (Mirdita et al. 2022).\nAlphafold models can be evaluated by the mean pLDDT, a per-residue confidence metric. It is stored in the B-factor fields of the mmCIF and PDB files available for download (although unlike a B-factor, higher pLDDT is better). The model confidence can vary greatly along a chain so it is important to consult the confidence when interpreting structural features. Very often, the lower confidence fragments are not product of a poor prediction but an indicator of protein disorder.\nAlphafold also partnered with EMBL-EBI and Uniprot and generated a huge curated database of proteins from model organisms (Varadi et al. 2022), the Alphafold database. This is an amazing resource that may be also very helpful for you. Just consider that this database increased from 48% to 76% the fraction of human proteome with structural data, and also it also means great increases in the case of other model organisms, like, including microorganisms and plants (Porta-Pardo et al. 2022).\n\n\n\n\n\nChanges in protein structural coverage in model organisms."
  },
  {
    "objectID": "advanced.html#lets-try-alphafold2.",
    "href": "advanced.html#lets-try-alphafold2.",
    "title": "From advanced homology modeling to deep Learning-based methods",
    "section": "Let’s try Alphafold2.",
    "text": "Let’s try Alphafold2.\nSection under construction!\nAs mentioned above, the grand breakthrough of Alphafold would not have been the same without the Colabfold, a free open tool that made the state-of-the-art of AI-fueled protein prediction available to everyone.\n\n\n\nColabFold GitHub repository\n\n\nThe Colabfold repository on GitHub contains links to several Python “notebooks” developed on Google Colab, a platform to develop and share Python scripts on a Jupyter Notebook format. Notebooks are very important also for reproducibility in computer sciences, as they allow you to have the background and details and the actual code in a single document and also execute it. You can share those notebooks very easily and also update quickly as they are stored in your Google Drive.\nColabfold allow you to run notebooks of Alphafold and RoseTTAfold for specific applications, allowing even to run a bunch of proteins in batch. You can see a more detailed description in Mirdita et al. (2022). We are using the Alphafold2_mmseqs2 notebook, that allow you most of the common features. You need to allow Colab to use your Google account.\n\n\n\n\n\nIntroducing your sequence in Colabfold\n\n\nThen paste your sequence and chose a name. For more accurate models you can click “use_amber” option. It will run a short Molecular Dynamics protocol that ultimately optimize the modeling, but it will also take some more time, so better try at home.\nAs you can see, an this is a recent feature, you can also add your own template. That will safe time, but of course without any guarantee. If you have a template of a related protein, like an alternative splicing or a disease mutant, I’d advise you to try with and without the template. You may surprise.\n\n\n\nExecuting Colabfold\n\n\nAt this point, you may execute the whole pipeline or may some more customization. MSA stage can be also optimized to reduce execution time, by reducing database or even by providing your own MSA. Very often you may want to fold a protein with different parameters, particularly in the Advanced Colabfold, which may very convenient to reuse an MSA from a previous run (although they recently updated servers for MMSeqs and made it really faster). If your proteins are in the same operon or by any other reason you think that they should have co-evolved, you prefer a “paired” alignment. But you can always do both.\nAdvanced settings are specially needed for protein-protein complexes. Also the number of recycling steps will improve your model, particularly for targets with no MSA info from used databases. Then you can just get your model (and companion info and plots) in your GDrive or download it.\nWhat do you think is the ideal protein for alphafold2? Do you think homology modeling is dead?"
  },
  {
    "objectID": "advanced.html#corollary-has-levinthals-paradox-folded",
    "href": "advanced.html#corollary-has-levinthals-paradox-folded",
    "title": "From advanced homology modeling to deep Learning-based methods",
    "section": "Corollary: Has Levinthal’s paradox “folded”?",
    "text": "Corollary: Has Levinthal’s paradox “folded”?\nThe development of Alphafold and the Alphafold structures Database in collaboration with EMBL-EBI has been the origin of a New Era. Scientific publications and journals worldwide published long articles about the meaning of this breakthrough in science and its applications in biotechnology and biomedicine1 and DeepMind claimed to have Solved a 50-years Grand Challenge in biochemistry. The coverage of the protein structure space has been greatly increased (Porta-Pardo et al. 2022).\nHowever, some scientists have claimed that Alphafold2 and RoseTTAfold actually “cheat” a bit as it does not really solve the problem but generate a deep learning pipeline that “bypass” the problem (Pederson 2021). In agreement with that, it has been shown that machine learning methods actually do not reproduce the expected folding pathways while improving the structures during the recycling steps Outeiral, Nissley, and Deane (n.d.).\nIn conclusion, I do believe that Levinthal’s paradox has not been (yet) fully solved, but clearly almost (Al-Janabi 2022), and solving it will probably reduce the limitations of Alphafold2. However, CASP15 is currently being held and maybe I will have to change my mind later this year."
  },
  {
    "objectID": "advanced.html#d-features-prediction",
    "href": "advanced.html#d-features-prediction",
    "title": "Advanced homology modeling",
    "section": "",
    "text": "By definition 1D features are protein features that can be decoded directly from the protein primary structure and represented as values (categories, %, …) associated to individual residues in the sequence. For instance, we can assign a secondary structure state (symbol or probability) to each residue. Many structure prediction methods implement or call third parties methods to predict secondary structure and other 1D features, as important additional information during modeling process.\nYou can find links to several 1D features prediction tools in the Modeling Resources section.\n\n\nSecondary structures are assigned to structures using DSSP (Define Secondary Structure of Proteins) algorithm, originally written in 1983 and updated several times throughout the years, being the last version from 2021 (available on GitHub). This algorithm classifies each residue considering its geometry and H-bonds prediction by comparison with pre-existing patterns in DSSP database. Remarkably, DSSP does not predict secondary structures, it just extracts this information from the 3D coordinates.\nProtein secondary structure prediction (PSSP) from protein sequences is based in the hypothesis that Segments of consecutive residues have preferences for certain secondary structure states. Similar to other methods in bioinformatics, including protein modeling, approaches to SS prediction evolved during the last 50 years (see Table 1).\nFirst generation methods rely on statistics approaches and prediction depends on assigning a set of prediction values to a residue \u000band then applying a simple algorithm to those numbers. I.e. apply a probability score based on \u000bsingle amino acid propensity. In the 1990’s, new algorithms included the information of the flanking residues (3-50 nearby amino acids) in the so-called Nearest Neighbor (N-N) Methods. These methods increased the accuracy in many cases but still had strong limitations, as they only considered three possible states (helix, strand or turn). Moreover, as you know from the secondary structure practice, β-strands predictions are more difficult and did not improve much thanks to N-N methods. Additionally, predicted helices and strands were usually too short.\nBy the end of 1990 decade, new methods boosted the accuracy to values near to 80%. These methods included two innovations, one conceptual and one methodological. The conceptual innovation was the inclusion of evolutionary information in the predictions, by considering the information of multiple sequence alignments or profiles. If a residue or a type of residue is evolutionary conserved, it is likely that it is important to define SS stretches. The second innovation was the use of neural networks (see below) in which multiple layers of sequence-to-structure predictions were compared with a independently trained networks (see PHD paper by Burkhard Rost here).\nSince the 2000s, most commonly used methods are meta-servers that compare several algorithms, mostly based o neural-networks, like JPred or SYMPRED, among others.\nIn the recent years, deep neural networks trained with large datasets have become the primary method for protein secondary structure prediction (and almost any other prediction in StrBio). In the Alphafold era (see next lesson), methods adapted from image processing or natural language processing (NLP) are also used (for instance in NetSurfP-3.0, see Høie et al. (2022)), allowing protein secondary structure predictions to focus on specific objectives, such as enhancing the quality of evolutionary information for protein modeling (Ismi, Pulungan, and Afiahayati 2022).\n\nEvolution of secondary structure prediction methods (modified from Ismi, Pulungan, and Afiahayati (2022)).\n\n\nGeneration\nMethod\nAccuracy\n\n\n1st: Statistics\nChow & Fassman (1974-)\n57%\n\n\n\nG OR (1978-)\n63-73.5%\n(Version V)\n\n\n2nd: Nearest Neighbor (N-N) methods\nPREDATOR (1996)\n75%\n\n\n\nNNSSP (1995)\n72%\n\n\n3rd: N-N neural network & evolutionary info\nAPSSP\nUp to 86%\n\n\n\nPsiPRED (1999-)\n75.7% (1999)\n84% (2019)\n\n\n\nPHD (1997)\n74%\n\n\n\nSAM (HHM profiles)\n76%\n\n\n4th: Multiple layers of info\nExtra layers of info, such as conserved domains, frequent patterns, contact maps or predicted residue solvent accessibility (2000s)\n&lt;80%\n\n\n5th generation\nSophisticated deep learning architectures and NLP (2010s, 2020s).\nRaptorX- Property (2018), SPIDER3 (2020) and Ne tSurfP-3.0 (2022), among others.\n&gt;80%\n\n\nMETA-Servers\nJ pre d4\n\n\n\n\nGeneSilico (Discontinued)\n\n\n\n\nSYM PRED\n\n\n\n\n\n\nMost PSSP methods use a three-state secondary structure, in which the secondary structure elements consist of helix (H), sheet (E), and coil (C). Helix and sheet are the two main conformations suggested in early times of structural biology by Linus Pauling. Coil (C) denotes an amino acid that does not fit both H and E.\n\n\n\n\nThe expression disorder denote protein stretches that cannot be assigned to any SS. They are usually dynamic/flexible, thus with high B-factor or even missing in crystal structures. These fragments show a low complexity and they are usually rich in polar residues, whereas aromatic residues are rarely found in disordered regions. These motifs are usually at the ends of proteins or domain boundaries (as linkers). Additionally, they are frequently related to specific functionalities, such in the case of proteolytic targets or protein-protein interactions (PPI). More rarely, large disordered domains can be conserved in protein families and associated with relevant functions, as in the case of some transcription factors, transcription regulators, kinases…\nThere are many methods and servers to predict disordered regions. You can see a list in the Wikipedia here or in the review by Atkins et al. (2015). The best-known server is DisProt, which uses a large curated database of intrinsically disordered proteins and regions from the literature, which has been recently improved to version 9 in 2022, as described in Quaglia et al. (2022).\nInterestingly, a low plDDT (see below) score in Alphafold2 models has been also suggested as a good indicator of protein disorder (Wilson, Choy, and Karttunen 2022).\n\n\n\nFigure 1: Examples of disordered regions. From Database of disordered regions.\n\n\nHydrophobic collapse is usually referred to as a key step in protein folding. Hydrophobic residues tend to be buried inside the protein, whereas hydrophilic, polar amino acids are exposed to the aqueous solvent.\n\n\n\nFigure 2: Hydrophobic collapse as a early step in protein folding. From Feenstra & Abeln, Introduction to Structural Bioinformatics.\n\n\nSolvent accessibility correlates with residue hydrofobicity \u000b(accessibility methods usually better \u000bperformance). Therefore, estimation of how likely each residue is exposed to the solvent or buried inside the protein is useful to obtain and analyze protein models. Moreover, this information is useful to predict PPIs as well as ligand binding or functional sites. Most methods only classify each residue into two groups: Buried, for those with relative accessibility probability &lt;16% and Exposed, for accessibility residues &gt;16%.\nMost common recent methods, like ProtSA or PROFacc, combine evolutionary information with neural networks to predict accessibility.\n\n\n\nIdentification of transmembrane motifs is also a key step in protein modeling. About 25-30% of human proteins contain transmembrane elements, most of them in alpha helices.\n\n\n\nFigure 3: Different topologies of transmembrane proteins\n\n\nThe PDBTM (Protein Data Bank of Transmembrane Proteins) is a comprehensive and up-to-date transmembrane protein selection. As of September 2022, it contains more than 7600 transmembrane proteins, 92.6% of them with alpha helices TM elements. This number of TM proteins is relatively low, as compared with more than 160k structures in PDB, as TM proteins are usually harder to purify and crystalization conditions are often elusive. Thus, although difficult, accurate predictions of TM motifs and overall protein topology can be essential to define protein architecture and identify domains that could be structurally or functionally studied independently.\n\n\n\nFigure 4: Different topologies of TM helices.\n\n\nCurrent state-of-the-art TM prediction protocols show an accuracy of 90% for definition of TM elements, but only a 80% regarding the protein topology. However, some authors claim that in some types of proteins, the accuracy is not over 70%, due to the small datasets of TM proteins. Most recent methods, based in deep-learning seem to have increased the accuracy to values near 90% for several groups of proteins (Hallgren et al. 2022).\n\n\n\nMany cellular functions are compartmentalized in the nucleus, mitochondria, endoplasmatic reticulum (ER), or other organules. Therefore, many proteins should be located in those compartments. That is achieved by the presence of some labels, in form of short peptidic sequences that regulate traffic and compartmentalization of proteins within the cells. Typically, N-terminal signals direct proteins to the mitochondrial matrix, ER, or peroxisomes, whereas nucleus traffic is regulated by nuclear localization signals (NLS) and nuclear export signals (NES).\nSimilarly, post-translational modifications very often occur in conserved motifs that contain target residues for phosphorylation or ubiquitination, among other modifications.\nThese short motifs are difficult to predict, as datasets of validated signals are small. The use of consensus sequences allowed predictions, although in many cases with a high level of uncertainty."
  },
  {
    "objectID": "advanced.html#maps",
    "href": "advanced.html#maps",
    "title": "Advanced homology modeling",
    "section": "From contact maps to pairwise high-res feature maps",
    "text": "From contact maps to pairwise high-res feature maps\n\n\n\n\n\nFigure 5: Contact-based map of representative proteins. The map represents a matrix of amino acid positions in the protein sequences (on both, the X and Y axis); with contacts indicated as blue dots. When a number of consecutive residues in the sequence interact the dots form diagonal stretches. Maps obtained at http://cmweb.enzim.hu/\n\n\nDuring the last decade, the introduction of residue-residue contact or distance maps prediction based on sequence co-evolution and deep learning started a revolution in the field that crystallize with the arrival of Alphafold2 and RoseTTAfold as major breakthroughs with great repercussions in diverse fields. As shown in Figure 3, residue-residue contact maps can be obtained from structures as a matrix that show close residues and show a pattern that clearly show differences between motifs and secondary structure stretches.\n\n\n\nFigure 6: Schematic of how co-evolution methods extract information about protein structure from a multiple sequence alignment (MSA). Image modified from doi: 10.5281/zenodo.1405369, which in turn was modified from Marks et al. (2011).\n\n\nAn accurate information of protein’s residue–residue contacts is sufficient to elucidate the fold of a protein (Olmea and Valencia 1997); however implementation of these maps in protein modeling is not trivial, as predicting that map is not always easy. The introduction of evolutionary coupling analysis (ECA), i.e., extract the residue coevolution from MSAs (Figure 4) improved contact maps and allowed their implementation for protein folding in several methods, like PSICOV (Jones et al. 2012) or Gremlin (Kamisetty, Ovchinnikov, and Baker 2013), among others. However, it should be noted for proteins without many sequence homologs, the predicted contacts were of low quality and insufficient for accurate contact-assisted protein modeling.\n\n\n\nFigure 7: Illustration of column pair and precision submatrix grouping for advanced prediction of contact maps. In the example, Columns 5 and 14 in the first family are aligned to columns 5 and 11 in the second family, respectively, so column pair (5,14) in the first family and the pair (5,11) in the second family are assigned to the same group. Accordingly, the two precision submatrices will be asigned to the same group. From Ma et al. (2015).\n\n\nThe next level of complexity in contact maps is their application to distantly related proteins (Figure 5). This kind of analysis entails processing a huge amount of information, which increases the computational resources requirements.\nDeep learning is a sub-field of machine learning which is based on artificial neural networks (NN). Neural networks were introduced actually in the late 40’s and 50’s, but they reappeared in the 2000’s thanks to the increase in computational capacities and, more recently, the use of GPUs. Briefly, a NN uses multiple interconnected layers to transform multiple inputs (MSAs, high-resolution contact-based maps…) into compound features that can be used to predict a complex output, like a 3D protein structure. As their name indicates, NNs attempt to simulate the behavior of the human brain that processes large amounts of data and can be trained to “learn” from that data. Deep learning is based on the use of multiple layer-NN to optimize and refine for accuracy.\nIn this context, the introduction of supervised machine learning methods that predict contacts from distant protein families, outperforms ECA methods by the use of multilayer neural networks Ma et al. (2015). These methods allowed the use of the so-called high resolution contact maps, which contains enriched information with not only contacts but also distances, and angles, represented in a heatmap-like probability scale.\n\n\n\n\n\nExample of high-resolution contact maps of 6MSP. From Yang et al. (2020)"
  },
  {
    "objectID": "advanced.html#threading-or-fold-recognition-methods",
    "href": "advanced.html#threading-or-fold-recognition-methods",
    "title": "Advanced homology modeling",
    "section": "Threading or Fold-recognition methods",
    "text": "Threading or Fold-recognition methods\nAs mentioned earlier, the introduction of HMM-based profiles during the first decade of this century led to a great improvement in template detection and protein modeling in the twilight zone, i.e., proteins with only distant homologs (<25-30% identity) in databases. Current version of SwissModel and the use of HHPred+Modeller already rely on HMM profiles for template identification and alignment. In order to exploit the power of HMM searches, those methods naturally evolved into iterative threading methods, based on multitemplate model construction, implemented in I-TASSER (Roy, Kucukural, and Zhang 2010), Phyre2 (L. A. Kelley et al. 2015), and RosettaCM (Song et al. 2013), among others. These methods methods are usually referred as Threading or Fold-recognition methods. Both terms can be often used interchangeably, although some authors see threading as any technique that uses structural information in addition to sequence information to identify remote homologies, while threading would be a more complex process of modeling including remote homologies and also modeling of pairwise amino acid interactions in the structure. Therefore, although we have already used HHPred along with the use of HHPred to identify templates for a subsequent modeling, could be indeed considered as threading.\n\n\n\nFigure 1: The idea behind fold-recognition is that instead of comparing sequences, we intend to compare structures. In the Frozen approximation (left), one residue is aligned with the template structure and then we evaluate the probability of the nearby residues in the query sequence to be in the same position than the equivalent in the template. On the other hand, Defrost methods use profiles to generate improved alignments that allow better starting points to the energy calculations during the iterative modeling steps. From Lawrence A. Kelley (2009).\n\n\nThe iterative threading assembly refinement (I-TASSER) from Yang Zhang lab is one of the most widely used threading methods and servers. This method was was ranked as the No 1 server for protein structure prediction in the community-wide CASP7, CASP8, CASP9, CASP10, CASP11, CASP12, CASP13, and CASP14 experiments. I-TASSER first generates three-dimensional (3D) atomic models from multiple threading alignments and iterative structural assembly simulations that are iteratively selected and improved. The quality of the template alignments (and therefore the difficulty of modeling the targets) is judged based on the statistical significance of the best threading alignment, i.e., the Z-score, which is defined as the energy score in standard deviation units relative to the statistical mean of all alignments.\n\n\n\nFigure 2: Flowchart of I-TASSER protein structure modeling. From Rigden (2017).\n\n\nFirst, I-TASSER uses Psi-BLAST against a curated databases to select sequence homologs and generate a sequence profile. That profile is used to predict secondary structure and generate multiple fragmented models using several programs. The top template hits from each threading program are then selected for the following steps. In the second stage, continuous fragments in threading alignments are excised from the template structures, and are used to assemble structural conformations of the sections that aligned well, with the unaligned regions (mainly loops/tails) built by ab initio modeling. The fragment assembly is performed using a modified replica-exchange Monte Carlo random simulation technique, which implements several replica simulations in parallel using different conditions that are periodically exchanged. Those simulations consider multiple parameters, including model statistics (stereochemical outliers, H-bond, hydrophobicity…), spatial restrains and amino acid pairwise contact predicions (see below). In each step, output models are clustered to select the representative ones for the next stage. A final refinement step include rotamers modeling and filtering out steric clashes.\nOne interesting thing about I-TASSER is that it is integrated within a server with many other applications, including some of the tools that I-TASSER uses and other advanced methods based by I-TASSER, like I-TASSER-MTD for large, multidomain proteins or C-I-TASSER that implements a deep learning step, similar to Alphafold2 (see below).\n\n\n\n\n\nFigure 3: RosettaCM Protocol. (A) Flowchart of the RosettaCM protocol. (B–D) RosettaCM conformational sampling. From Song et al. (2013).\n\n\nRosettaCM is an advanced homology modeling or threading algorithm by the Baker lab, implemented in Rosetta software and the Robetta webserver. RosettaCM assemblies the model by recombining aligned segments in a set of selected templates and close the model by a minimization of the junctions between segments by fragments torsion and iterative optimization steps that include Monte Carlo sampling. Finally, an all-atom refinement towards a minimum of free energy (Song et al. 2013)."
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Modeling Resources",
    "section": "",
    "text": "Disclaimer\n\n\n\nThis is not a comprehensive list of Protein Modeling resources. Rather, it contains some of the references, methods, and online servers that I found useful through the years.\nMost useful links (IMHO) are highlighted in bold. Other (many) tools may be useful for you, feel free to let me know and I’ll update the list.\n\n\n\n\n\n\n\n\nNote\n\n\n\nLinks checked on 28/September/2023, let me know if you find any broken link.\n\n\n\n1 Template search\n\nBLAST: https://blast.ncbi.nlm.nih.gov/Blast.cgi\nHHPRED: https://toolkit.tuebingen.mpg.de/tools/hhpred\nHHblits: https://toolkit.tuebingen.mpg.de/tools/hhblits\nJackHMMER: https://www.ebi.ac.uk/Tools/hmmer/search/jackhmmer\n\nRef. https://nar.oxfordjournals.org/content/46/W1/W200\n\n\n\n\n2 Secondary structure and 1D features services\n\nJpred4: http://www.compbio.dundee.ac.uk/jpred/\n\nSecondary structure prediction\nRef. http://nar.oxfordjournals.org/content/early/2015/04/16/nar.gkv332\n\nPsiPred : http://bioinf.cs.ucl.ac.uk/psipred/\n\nSecondary structure prediction\nMEMSAT-SVM (Membrane Helix Prediction)\nRef: https://academic.oup.com/nar/article/47/W1/W402/5480136\n\nMULTICOM Toolbox: http://sysbio.rnet.missouri.edu/multicom_toolbox/web%20services.html\n\nPulls together protein structure and structural feature prediction tools.\n⚠️Server currently offline. Application available on GitHub: https://github.com/multicom-toolbox\n\nSCRATCH: http://scratch.proteomics.ics.uci.edu/\n\nMetaserver with a wide range of 1D-3D prediction tools.\n\nSYMPRED: http://www.ibi.vu.nl/programs/sympredwww/\n\nConsensus secondary structure prediction metaserver\n\nMESSA: http://prodata.swmed.edu/MESSA/MESSA.cgi\n\n1D features Metaserver\nRef.https://bmcbiol.biomedcentral.com/articles/10.1186/1741-7007-10-82\n\nDeepTMHMM: https://dtu.biolib.com/DeepTMHMM\n\nDeep-learning 2022 version of the classic TMHMM predictor of transmembrane helices\nRef. https://www.biorxiv.org/content/10.1101/2022.04.08.487609v1\n\nPhobius: https://www.ebi.ac.uk/Tools/pfa/phobius/\n\nPrediction of transmembrane topology and signal peptides from the amino acid sequence of a protein.\n\nTopCons: http://topcons.cbr.su.se/\n\nConsensus prediction of membrane protein topology and signal peptides\nRef. https://academic.oup.com/nar/article-lookup/doi/10.1093/nar/gkv485\n\nPSORT: https://psort.hgc.jp/\n\nSeveral localization signals\n\nPRED-TMMB: http://bioinformatics.biol.uoa.gr/PRED-TMBB/\n\nPredicion of beta-barrel TMEs & topology (HMM-based)\n\nPROF-TMF: https://open.predictprotein.org/\n\nPredicion of beta-barrel TMEs (PredictProtein Suite)\n\nNLStradamus: http://www.moseslab.csb.utoronto.ca/NLStradamus/\n\nPrediction of NLS\n\nSulfinator: https://web.expasy.org/sulfinator/\n\nPrediction of disulfide bonds\n\nDTU Tech resources: https://services.healthtech.dtu.dk/\n\nA collection of molecular biology tools, including a number of services for 1D features prediction, such as DeepTMHMM (Hallgren et al. 2022) or NetSurfP (Høie et al. 2022).\n\n\n\n\n\n3 Protein modeling\n\nSwissModel (Waterhouse et al. 2018): https://swissmodel.expasy.org/\nPsiPRED (Buchan and Jones 2019): http://bioinf.cs.ucl.ac.uk/psipred/\n\nFold recognition server (among other tools)\n\nRaptorX (Wang et al. 2017): http://raptorx.uchicago.edu/ContactMap/\n\nDistance-based Protein Folding Powered by Deep Learning\n\nPhyre2 (Kelley et al. 2015): http://www.sbg.bio.ic.ac.uk/~phyre2/html/page.cgi?id=index\n\nFold recognition & fragment assembler\n\nRobetta server: https://robetta.bakerlab.org/\n\nSeveral methods, including RosettaCM (Song et al. 2013) and RoseTTAFOLD (Baek et al. 2021; Baek et al., n.d.)\n\nModWeb (Pieper et al. 2014): https://modbase.compbio.ucsf.edu/modweb/\n\nWebserver using MODELLER (free registration required)\n\nColabFold (Mirdita et al. 2022): https://github.com/sokrypton/ColabFold\n\nSeveral notebooks available\n\nDeepMind’s AlphaFold colab: https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb\nOpenfold (Ahdritz et al., n.d.) Colab: https://colab.research.google.com/github/aqlaboratory/openfold/blob/main/notebooks/OpenFold.ipyn\nUnifold (Ziyao Li et al., n.d.) Colab: https://colab.research.google.com/github/dptech-corp/Uni-Fold/blob/main/notebooks/unifold.ipynb\nESM Metagenomic Atlas (DDBB & tools, Lin et al. (2023)): https://esmatlas.com/about\nPymolFold: A handy Pymol script that calls the ESM-Fold API\n\nhttps://github.com/JinyuanSun/PymolFold\nWeb version: http://103.79.77.89:8501/\n\nZhang server: https://zhanggroup.org/services/\n\nMultiple methods, including I-TASSER (Roy, Kucukural, and Zhang 2010), C-I-TASSER (Zheng et al. 2021) or I-TASSER-MTD, among others.\n\n\n\n\n4 Model quality assessment\n\nQMEAN & QMEANDisCo (Studer et al. 2020): https://swissmodel.expasy.org/qmean/\nModfold (McGuffin et al. 2021): https://www.reading.ac.uk/bioinf/ModFOLD/\nVoroMQA (Olechnovič and Venclovas 2019): http://bioinformatics.ibt.lt/wtsam/voromqa\nDeepUMQA (Guo et al. 2022): http://zhanglab-bioinf.com/DeepUMQA/\n\n\n\n5 Other resources\n\nDALI (Holm 2022): http://ekhidna2.biocenter.helsinki.fi/dali/\nFoldSeek (Kempen et al. 2023): https://search.foldseek.com/search\n\nFast search for structural similarities\n\nFatCat (Zhanwen Li et al. 2020): http://fatcat.godziklab.org/fatcat/fatcat_pair.html\n\nStructural alignment tool.\n\nLGA: http://proteinmodel.org/AS2TS/LGA/lga.html\n\nLGA program is being developed for structure comparative analysis of two selected 3D protein structures or fragments of 3D protein structures\nRef. https://academic.oup.com/nar/article-lookup/doi/10.1093/nar/gkg571\n\nGalaxy Refine: http://galaxy.seoklab.org/cgi-bin/submit.cgi?type=REFINE\n\nA server for automatically refining protein model structures.\nRef. http://www.ncbi.nlm.nih.gov/pubmed/23737448\n\nGalaxy Refine2: galaxy.seoklab.org/cgi-bin/submit.cgi?type=REFINE2\n\n&lt;300 aa\nRef:https://academic.oup.com/nar/article/47/W1/W451/5475172\n\nHOMCOS: http://homcos.pdbj.org/\n\nModeling of 3D Structures of Complexes\nRef. http://link.springer.com/article/10.1007/s10969-016-9208-y?wt_mc=Internal.Event.1.SEM.ArticleAuthorOnlineFirst\n\npyDockWEB: https://life.bsc.es/pid/pydockweb\n\nPrediction of protein-protein interactions (hetero-oligomers modeling)\n\nHex: http://hexserver.loria.fr/\n\nPrediction of protein-protein interactions (homo- & hetero-oligomers modeling)\nRef. https://onlinelibrary.wiley.com/doi/full/10.1002/prot.24433\n\nDaReUs-Loop: https://bioserv.rpbs.univ-paris-diderot.fr/services/DaReUS-Loop/\n\nModeling loops\nRef. https://www.nature.com/articles/s41598-018-32079-w\n\nGalaxyLoop: http://galaxy.seoklab.org/cgi-bin/submit.cgi?type=LOOP\n\nLoops refining\nRef. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0113811\n\nExpasy proteomics tools: https://www.expasy.org/proteomics\n\nList of qMultiple links and resources\n\nProtein modeling links @Sali Lab: https://salilab.org/bioinformatics_resources.html\nHomology modeling @Proteopedia:\n\nhttps://proteopedia.org/wiki/index.php/Homology_model\nhttps://proteopedia.org/wiki/index.php/User:Wayne_Decatur/Homology_Modeling\n\nList of protein structure prediction software @Wikipedia: https://en.wikipedia.org/wiki/List_of_protein_structure_prediction_software\n\n\n\n\n\n\nReferences\n\nAhdritz, Gustaf, Nazim Bouatta, Christina Floristean, Sachin Kadyan, Qinghui Xia, William Gerecke, Timothy J. O’Donnell, et al. n.d. “OpenFold: Retraining AlphaFold2 Yields New Insights into Its Learning Mechanisms and Capacity for Generalization.” https://doi.org/10.1101/2022.11.20.517210.\n\n\nBaek, Minkyung, Ivan Anishchenko, Ian R. Humphreys, Qian Cong, David Baker, and Frank DiMaio. n.d. “Efficient and Accurate Prediction of Protein Structure Using RoseTTAFold2.” https://doi.org/10.1101/2023.05.24.542179.\n\n\nBaek, Minkyung, Frank DiMaio, Ivan Anishchenko, Justas Dauparas, Sergey Ovchinnikov, Gyu Rie Lee, Jue Wang, et al. 2021. “Accurate prediction of protein structures and interactions using a three-track neural network.” Science (New York, N.Y.) 373 (6557): 871–76. https://doi.org/10.1126/science.abj8754.\n\n\nBuchan, Daniel W A, and David T Jones. 2019. “The PSIPRED Protein Analysis Workbench: 20 Years On.” Nucleic Acids Research 47 (W1): W402–7. https://doi.org/10.1093/nar/gkz297.\n\n\nGuo, Sai-Sai, Jun Liu, Xiao-Gen Zhou, and Gui-Jun Zhang. 2022. “DeepUMQA: ultrafast shape recognition-based protein model quality assessment using deep learning.” Bioinformatics (Oxford, England) 38 (7): 1895–1903. https://doi.org/10.1093/bioinformatics/btac056.\n\n\nHallgren, Jeppe, Konstantinos D. Tsirigos, Mads Damgaard Pedersen, José Juan Almagro Armenteros, Paolo Marcatili, Henrik Nielsen, Anders Krogh, and Ole Winther. 2022. “DeepTMHMM Predicts Alpha and Beta Transmembrane Proteins Using Deep Neural Networks.” https://doi.org/10.1101/2022.04.08.487609.\n\n\nHøie, Magnus Haraldson, Erik Nicolas Kiehl, Bent Petersen, Morten Nielsen, Ole Winther, Henrik Nielsen, Jeppe Hallgren, and Paolo Marcatili. 2022. “NetSurfP-3.0: Accurate and Fast Prediction of Protein Structural Features by Protein Language Models and Deep Learning.” Nucleic Acids Research 50 (W1): W510–15. https://doi.org/10.1093/nar/gkac439.\n\n\nHolm, Liisa. 2022. “Dali Server: Structural Unification of Protein Families.” Nucleic Acids Research 50 (W1): W210–15. https://doi.org/10.1093/nar/gkac387.\n\n\nKelley, L. A., S. Mezulis, C. M. Yates, M. N. Wass, and M. J. Sternberg. 2015. “The Phyre2 Web Portal for Protein Modeling, Prediction and Analysis.” Nat Protoc 10 (6): 845–58. https://doi.org/10.1038/nprot.2015.053.\n\n\nKempen, Michel van, Stephanie S. Kim, Charlotte Tumescheit, Milot Mirdita, Jeongjae Lee, Cameron L. M. Gilchrist, Johannes Söding, and Martin Steinegger. 2023. “Fast and Accurate Protein Structure Search with Foldseek.” Nature Biotechnology, May, 1–4. https://doi.org/10.1038/s41587-023-01773-0.\n\n\nLi, Zhanwen, Lukasz Jaroszewski, Mallika Iyer, Mayya Sedova, and Adam Godzik. 2020. “FATCAT 2.0: towards a better understanding of the structural diversity of proteins.” Nucleic Acids Research 48 (W1): W60–64. https://doi.org/10.1093/nar/gkaa443.\n\n\nLi, Ziyao, Xuyang Liu, Weijie Chen, Fan Shen, Hangrui Bi, Guolin Ke, and Linfeng Zhang. n.d. “Uni-Fold: An Open-Source Platform for Developing Protein Folding Models Beyond AlphaFold.” https://doi.org/10.1101/2022.08.04.502811.\n\n\nLin, Zeming, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, et al. 2023. “Evolutionary-Scale Prediction of Atomic-Level Protein Structure with a Language Model.” Science 379 (6637): 1123–30. https://doi.org/10.1126/science.ade2574.\n\n\nMcGuffin, Liam J., Fahd M. F. Aldowsari, Shuaa M. A. Alharbi, and Recep Adiyaman. 2021. “ModFOLD8: accurate global and local quality estimates for 3D protein models.” Nucleic Acids Research 49 (W1): W425–30. https://doi.org/10.1093/nar/gkab321.\n\n\nMirdita, Milot, Konstantin Schütze, Yoshitaka Moriwaki, Lim Heo, Sergey Ovchinnikov, and Martin Steinegger. 2022. “ColabFold: making protein folding accessible to all.” Nature Methods 19 (6): 679–82. https://doi.org/10.1038/s41592-022-01488-1.\n\n\nOlechnovič, Kliment, and Česlovas Venclovas. 2019. “VoroMQA web server for assessing three-dimensional structures of proteins and protein complexes.” Nucleic Acids Research 47 (W1): W437–42. https://doi.org/10.1093/nar/gkz367.\n\n\nPieper, Ursula, Benjamin M. Webb, Guang Qiang Dong, Dina Schneidman-Duhovny, Hao Fan, Seung Joong Kim, Natalia Khuri, et al. 2014. “ModBase, a database of annotated comparative protein structure models and associated resources.” Nucleic Acids Research 42 (Database issue): D336–346. https://doi.org/10.1093/nar/gkt1144.\n\n\nRoy, A., A. Kucukural, and Y. Zhang. 2010. “I-TASSER: a unified platform for automated protein structure and function prediction.” Nat Protoc 5 (4): 725–38. https://doi.org/nprot.2010.5 [pii] 10.1038/nprot.2010.5.\n\n\nSong, Yifan, Frank DiMaio, Ray Yu-Ruei Wang, David Kim, Chris Miles, TJ Brunette, James Thompson, and David Baker. 2013. “High-Resolution Comparative Modeling with RosettaCM.” Structure 21 (10): 1735–42. https://doi.org/https://doi.org/10.1016/j.str.2013.08.005.\n\n\nStuder, Gabriel, Christine Rempfer, Andrew M. Waterhouse, Rafal Gumienny, Juergen Haas, and Torsten Schwede. 2020. “QMEANDisCo-distance constraints applied on model quality estimation.” Bioinformatics (Oxford, England) 36 (6): 1765–71. https://doi.org/10.1093/bioinformatics/btz828.\n\n\nWang, Sheng, Siqi Sun, Zhen Li, Renyu Zhang, and Jinbo Xu. 2017. “Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model.” PLoS computational biology 13 (1): e1005324. https://doi.org/10.1371/journal.pcbi.1005324.\n\n\nWaterhouse, Andrew, Martino Bertoni, Stefan Bienert, Gabriel Studer, Gerardo Tauriello, Rafal Gumienny, Florian T Heer, et al. 2018. “SWISS-MODEL: Homology Modelling of Protein Structures and Complexes.” Nucleic Acids Research 46 (W1): W296–303. https://doi.org/10.1093/nar/gky427.\n\n\nZheng, Wei, Chengxin Zhang, Yang Li, Robin Pearce, Eric W. Bell, and Yang Zhang. 2021. “Folding non-homologous proteins by coupling deep-learning contact maps with I-TASSER assembly simulations.” Cell Reports Methods 1 (3): 100014. https://doi.org/10.1016/j.crmeth.2021.100014."
  },
  {
    "objectID": "advanced.html#sec-threading",
    "href": "advanced.html#sec-threading",
    "title": "Advanced homology modeling",
    "section": "",
    "text": "As mentioned earlier, the introduction of HMM-based profiles during the first decade of this century led to a great improvement in template detection and protein modeling in the twilight zone, i.e., proteins with only distant homologs (&lt;25-30% identity) in databases. In order to exploit the power of HMM searches, those methods naturally evolved into iterative threading methods, based on multitemplate model construction, implemented in I-TASSER (Roy, Kucukural, and Zhang 2010), Phyre2 (L. A. Kelley et al. 2015), and RosettaCM (Song et al. 2013), among others. These methods are usually referred to as Threading or Fold-recognition methods. Note that the classification of modeling methods is often blurry. The current version of SwissModel and the use of HHPred+Modeller already rely on HMM profiles for template identification and alignment; being thus strictly also fold-recognition methods.\nBoth terms can be often used interchangeably, although some authors see Fold-Recognition as any technique that uses structural information in addition to sequence information to identify remote homologies, while Threading would refer to a more complex process of modeling including remote homologies and also the modeling of pairwise amino acid interactions in the structure. Therefore, HHPRED is a fold-recognition method and its use along with Modeller, could be indeed considered threading.\n\n\n\nFigure 1: The idea behind fold-recognition is that instead of comparing sequences, we intend to compare structures. In the Frozen approximation (left), one residue is aligned with the template structure and then we evaluate the probability of the nearby residues in the query sequence to be in the same position than the equivalent in the template. On the other hand, Defrost methods use profiles to generate improved alignments that allow better starting points to the energy calculations during the iterative modeling steps. From Lawrence A. Kelley (2009).\n\n\nThe Iterative Threading ASSembly Refinement (I-TASSER) from Yang Zhang lab is one of the most widely used threading methods and servers. This method was was ranked as the No 1 server for protein structure prediction in the community-wide CASP7, CASP8, CASP9, CASP10, CASP11, CASP12, CASP13, and CASP14 experiments. I-TASSER first generates three-dimensional (3D) atomic models from multiple threading alignments and iterative structural assembly simulations that are iteratively selected and improved. The quality of the template alignments (and therefore the difficulty of modeling the targets) is judged based on the statistical significance of the best threading alignment, i.e., the Z-score, which is defined as the energy score in standard deviation units relative to the statistical mean of all alignments.\n\n\n\nFigure 2: Flowchart of I-TASSER protein structure modeling. From Rigden (2017).\n\n\nFirst, I-TASSER uses Psi-BLAST against curated databases to select sequence homologs and generate a sequence profile. That profile is used to predict the secondary structure and generate multiple fragmented models using several programs. The top template hits from each threading program are then selected for the following steps. In the second stage, continuous fragments in threading alignments are excised from the template structures and are used to assemble structural conformations of the sections that aligned well, with the unaligned regions (mainly loops/tails) built by ab initio modeling. The fragment assembly is performed using a modified replica-exchange Monte Carlo random simulation technique, which implements several replica simulations in parallel using different conditions that are periodically exchanged. Those simulations consider multiple parameters, including model statistics (stereochemical outliers, H-bond, hydrophobicity…), spatial restraints and amino acid pairwise contact predictions (see below). In each step, output models are clustered to select the representative ones for the next stage. A final refinement step includes rotamers modeling and filtering out steric clashes.\nOne interesting thing about I-TASSER is that it is integrated within a server with many other applications, including some of the tools that I-TASSER uses and other advanced methods based on I-TASSER, like I-TASSER-MTD for large, multidomain proteins or C-I-TASSER that implements a deep learning step, similar to Alphafold2 (see next section).\n\n\n\nFigure 3: RosettaCM Protocol. (A) Flowchart of the RosettaCM protocol. (B–D) RosettaCM conformational sampling. From Song et al. (2013).\n\n\nRosettaCM is an advanced homology modeling or threading algorithm by the Baker lab, implemented in Rosetta software and the Robetta webserver. RossetaCM provides accurate models by breaking up the sequence into fragments that are aligned to a set of selected templates, generating accurate models by a threading processes that uses different fragments from each of the templates. Additionally it uses minor ab initio folding to fill the residues that could not be assigned during the threading. Then, the model is closed by iterative optimization steps that include Monte Carlo sampling. Finally, an all-atom refinement towards a minimum of free energy (Song et al. 2013).\n\n\n\n\n\n\nPuzzling nomenclature: comparative, homology or ab initio modeling?\n\n\n\nDe novo or ab initio modeling used to mean modeling a protein without using a template. However, this strict definition is blurred in the 2000s (decade) by advanced methods that use fragments. Threading protocols such as RosettaCM and I-Tasser, among others, use fragments that may or may not come from homologous protein structures or not. Therefore, they cannot be classified as homology modeling, but they are sometimes referred to as comparative or hybrid methods."
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "StrBio UAM",
    "section": "",
    "text": "Please let me know if you find some mistake or a missing reference. Definitely, I’ll appreciate any suggestion, request or correction. You can reach me by email, (f.k.a. Twitter) or .",
    "crumbs": [
      "StrBio UAM"
    ]
  },
  {
    "objectID": "ai.html#the-evolution-of-the-field-in-one-tweet",
    "href": "ai.html#the-evolution-of-the-field-in-one-tweet",
    "title": "State-of-the-art protein modeling (in 2022)",
    "section": "The evolution of the field in one tweet:",
    "text": "The evolution of the field in one tweet:"
  },
  {
    "objectID": "ai.html#footnotes",
    "href": "ai.html#footnotes",
    "title": "Protein modeling in the AlphaFold era",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee https://www.wired.com/story/without-code-for-deepminds-protein-ai-this-lab-wrote-its-own/↩︎\nhttps://www.bbc.com/news/science-environment-57929095\nhttps://www.forbes.com/sites/robtoews/2021/10/03/alphafold-is-the-most-important-achievement-in-ai-ever/\nhttps://elpais.com/ciencia/2021-07-22/la-forma-de-los-ladrillos-basicos-de-la-vida-abre-una-nueva-era-en-la-ciencia.html↩︎"
  },
  {
    "objectID": "ai.html#the-evolution-of-the-field-in-one-x-wire",
    "href": "ai.html#the-evolution-of-the-field-in-one-x-wire",
    "title": "State-of-the-art protein modeling (in 2022)",
    "section": "2021-2023 - The evolution of the field in one X wire",
    "text": "2021-2023 - The evolution of the field in one X wire"
  },
  {
    "objectID": "ai.html#the-evolution-of-the-field-in-one-iconify-x-twitter-wire",
    "href": "ai.html#the-evolution-of-the-field-in-one-iconify-x-twitter-wire",
    "title": "State-of-the-art protein modeling (in 2022)",
    "section": "2021-2023 - The evolution of the field in one  wire",
    "text": "2021-2023 - The evolution of the field in one  wire"
  },
  {
    "objectID": "ai.html#the-evolution-of-the-field-in-one-iconify-exploding-head-wire",
    "href": "ai.html#the-evolution-of-the-field-in-one-iconify-exploding-head-wire",
    "title": "State-of-the-art protein modeling (in 2022)",
    "section": "2021-2023 - The evolution of the field in one  wire",
    "text": "2021-2023 - The evolution of the field in one  wire"
  },
  {
    "objectID": "ai.html#the-evolution-of-the-field-in-one-iconify-ri-x-twitter-wire",
    "href": "ai.html#the-evolution-of-the-field-in-one-iconify-ri-x-twitter-wire",
    "title": "State-of-the-art protein modeling (in 2022)",
    "section": "2021-2023 - The evolution of the field in one  wire",
    "text": "2021-2023 - The evolution of the field in one  wire"
  },
  {
    "objectID": "ai.html#the-evolution-of-the-field-in-one-iconify-fa6-brands-x-twitter-wire",
    "href": "ai.html#the-evolution-of-the-field-in-one-iconify-fa6-brands-x-twitter-wire",
    "title": "Protein modeling in the post-AlphaFold era",
    "section": "2021-2023 - The evolution of the field in one  wire",
    "text": "2021-2023 - The evolution of the field in one  wire"
  },
  {
    "objectID": "intro.html#quick-exercise",
    "href": "intro.html#quick-exercise",
    "title": "Introduction",
    "section": "2.3 Quick exercise",
    "text": "2.3 Quick exercise\nExplore the structure below and try to understand its structure. Then answer the question.\n    \n    \n    \nHow many unique protein chains are there is this protein?\n\n 1 2 3 &gt;3\n\nWhich structural class is the protein above?\n\n All-α All β α/β α+β Small\n\nAs you can see, as the protein is larger, classification gets more difficult. Moreover, as fold space has become more and more complex, these types of classifications have been adjusted and extended such that a complete hierarchy is created. The most commonly referred approaches to this sort of classification are those used by SCOP and CATH databases, as we will see in the Structural Databases section.",
    "crumbs": [
      "Background",
      "Introduction"
    ]
  },
  {
    "objectID": "homology.html#are-protein-structures-predictable-at-all",
    "href": "homology.html#are-protein-structures-predictable-at-all",
    "title": "Homology Modeling",
    "section": "",
    "text": "The properties of the amino acids determine the Φ and Ψ angles that eventually shape the higher structural levels. However, protein folding can be more complex, as it should be coupled with protein synthesis.\nOne can imagine that the complexity and diversity of protein structures in nature can be enormous. Indeed, John Kendrew and his co-workers seemed very disappointed in the determination of the first three-dimensional globular structure, the myoglobin in 1958 (Kendrew et al. 1958):\n\nPerhaps the most remarkable features of the molecule are its complexity and its lack of symmetry. The arrangement seems to be almost totally lacking in the kind of regularities which one instinctively anticipates, and it is more complicated that has been anticipated by any theory of protein structure.\n\nNot much later, in 1968, Cyrus Levinthal (1922–1990) published the so-called Levinthal’s paradox, stating that proteins fold in nano/milliseconds, but even for small peptides it will take a huge time to test the astronomical number of possible conformations. Say a 100 aa small protein; it will have 99 peptidic bonds and 198 different phi and psi angles. Assuming only 3 alternative conformations for each bond, it will yield 3198 (= 2.95 x 1095) possible conformations. If we design a highly efficient algorithm that tests 1 conformation per nanosecond:\n 2.95 x 1085 secs = 9x1067 billions years\nConsidering that the age of the universe is 13.8 billion years, predicting protein structures does not seem an easy task.\nIn this context, a very simple experiment 50 years ago, led some light on the protein folding mechanism. Cristian Anfisen was able to completely denature (unfold) the Ribonuclease A, by the addition of reducing agents and urea under heat treatment, and subsequently switch to normal conditions that allow the protein to re-fold fully functional. This experiment indicates that the amino acid sequence dictates the final structure. Notwithstanding some relevant exceptions, this has been largely confirmed.\n\n\n\nFigure 3: The Anfinsen Dogma: Amino acid sequence dictated the final structure. From Anfinsen (1973) .\n\n\nOne can imagine that in vivo native structures of proteins look-alike the lowest free energy conformation, i.e., the global energy minimum. That is the basis of the funnel model of protein folding, which assumes that the number of possible conformations is reduced when a local energy minimum is achieved, constituting a path for the folding process.\n\n\n\nFigure 4: Schematic diagram of a protein folding energy landscape according to the funnel model. Denatured molecules at the top of the funnel might fold to the native state by a myriad of different routes, some of which involve transient intermediates (local energy minima) whereas others involve significant kinetic traps (misfolded states). From Radford (2000).\n\n\n\n\n\n\n\n\nConclusion\n\n\n\nPrediction of protein structures is possible, as protein folding relies only on the protein sequence, but it will require virtually infinite time and computational resources …or highly efficient ones, as we will see.\n\n\nHomology modeling is one of the most convenient tricks to get around this limitation. Basically, the strategy is to add more layers of additional information to amino acid properties, namely evolutionary conservation of sequences and structures.\nVery often, you already have some information about your protein before you create models. For example, if it is an enzyme, you may have discovered the catalytic residues or the substrate interaction region. It is also advisable to look in the literature, in particular to see if there is a companion paper to the corresponding PDB structure(s) that may be available or that you may be able to find and use as a template(s) for modeling."
  },
  {
    "objectID": "ai.html#wanna-try-alphafold",
    "href": "ai.html#wanna-try-alphafold",
    "title": "Protein modeling in the AlphaFold era",
    "section": "Wanna try Alphafold?",
    "text": "Wanna try Alphafold?\nSection under construction!\nAs mentioned above, the grand breakthrough of Alphafold would not have been the same without the Colabfold, a free open tool that made the state-of-the-art of AI-fueled protein prediction available to everyone.\n\n\n\nFigure 8: ColabFold GitHub repository\n\n\nThe Colabfold repository on GitHub contains links to several Python notebooks developed on Google Colab, a platform to develop and share Python scripts on a Jupyter Notebook format. Notebooks are very important also for reproducibility in computer sciences, as they allow you to have the background and details and the actual code in a single document and also execute it. You can share those notebooks very easily and also update quickly as they are stored in your Google Drive.\nColabfold allow you to run notebooks of Alphafold, RoseTTAfold, and ESMFold for specific applications, allowing even to run a bunch of proteins in batch. You can see a more detailed description in Mirdita et al. (2022). We are using the Alphafold2_mmseqs2 notebook, that allow you most of the common features. You need to allow Colab to use your Google account.\n\n\n\nFigure 9: Introducing your sequence in Colabfold\n\n\nThen paste your sequence and chose a name. For more accurate models you can click “use_amber” option. It will run a short Molecular Dynamics protocol that ultimately optimize the modeling, but it will also take some more time, so better try at home.\nAs you can see, an this is a recent feature, you can also add your own template, which combines the classical “homology modeling” based upon a single template with the advanced AlphaFold model construction method. That will safe time, but of course without any guarantee. If you have a template of a related protein, like an alternative splicing or a disease mutant, I’d advise you to try with and without the template. You may surprise.\n\n\n\nFigure 10: Executing Colabfold\n\n\nAt this point, you may execute the whole pipeline or may some more customization. MSA stage can be also optimized to reduce execution time, by reducing database or even by providing your own MSA. Very often you may want to fold a protein with different parameters, particularly in the Advanced Colabfold, which may very convenient to reuse an MSA from a previous run (although they recently updated servers for MMSeqs and made it really faster). If your proteins are in the same operon or by any other reason you think that they should have co-evolved, you prefer a “paired” alignment. But you can always do both.\nAdvanced settings are specially needed for protein-protein complexes. Also the number of recycling steps will improve your model, particularly for targets with no MSA info from used databases. Then you can just get your model (and companion info and plots) in your GDrive or download it.\nWhat do you think is the ideal protein for AlphaFold? Do you think homology modeling is dead?"
  },
  {
    "objectID": "1d.html",
    "href": "1d.html",
    "title": "1D Features",
    "section": "",
    "text": "By definition 1D features are protein features that can be decoded directly from the protein primary structure and represented as values (categories, %, …) associated to individual residues in the sequence. For instance, we can assign a secondary structure state (symbol or probability) to each residue. Many structure prediction methods implement or call third parties methods to predict secondary structure and other 1D features, as important additional information during modeling process.\nYou can find links to several 1D features prediction tools in the Modeling Resources section."
  },
  {
    "objectID": "1d.html#protein-secondary-structure-prediction",
    "href": "1d.html#protein-secondary-structure-prediction",
    "title": "1D Features",
    "section": "Protein secondary structure prediction",
    "text": "Protein secondary structure prediction\n\nMultiple state of secondary structures\nSecondary structures are assigned to structures using DSSP (Define Secondary Structure of Proteins) algorithm, originally written in 1983 and updated several times throughout the years, being the last version from 2021 (available on GitHub). This algorithm classifies each residue considering its geometry and H-bonds prediction by comparison with pre-existing patterns in DSSP database. Remarkably, DSSP does not predict secondary structures, it just extracts this information from the 3D coordinates.\nMost protein secondary structure prediction (PSSP) methods use a three-state secondary structure, in which the secondary structure elements consist of helix (H), sheet (E), and coil (C). Helix and sheet are the two main conformations suggested in early times of structural biology by Linus Pauling (see Intro Lesson), whereas Coil (C) denotes an amino acid that does not fit both H and E. This representation is very important and still used by many structural biologist, however it imposes several limitations that cannot be overlooked. This is because three secondary structure states are only a coarse-grained representation of the backbone structure with helical and sheet residues that very often can deviate from the standard helix and sheet conformations.\nAlready in the 80s, a eight-state secondary structure was proposed (see Ismi, Pulungan, and Afiahayati (2022)), consisting in α-helix (H), 310-helix (G), parallel/anti-parallel β-sheet (E), isolated β-bridge (B), bend (S), turn (T), π-helix (I) and coli (C). In fact, DSSP, defines the eight states in experimentally obtained structures and it also contains transformations that rule the mapping of eight-state secondary structures to the three-states.\nMore recently, in 2020, four-state and five-state PSSP were proposed to simplify predictions and increase the true-positives. The reason for proposing four-state and five-state PSSP was the imbalanced samples of each class: isolated β-bridge (B) and bend (S) have a small number of samples and low true-positive rates. In five-state PSSP, B and S are considered as C, whereas in four-state PSSP, B, S, and G are considered as C. Moreover, 75% of π-helix (I) was located at the beginning or the end of an a-helix structure (H), so it was categorized as H. The full potential of this new categories is still to be analyzed in detail\n\n\nEvolution of Prediction methods\nProtein secondary structure prediction (PSSP) from protein sequences is based in the hypothesis that Segments of consecutive residues have preferences for certain secondary structure states. Similar to other methods in bioinformatics, including protein modeling, approaches to SS prediction evolved during the last 50 years (see Table 1).\nFirst generation methods rely on statistics approaches and prediction depends on assigning a set of prediction values to a residue \u000band then applying a simple algorithm to those numbers. I.e. apply a probability score based on \u000bsingle amino acid propensity. In the 1990’s, new algorithms included the information of the flanking residues (3-50 nearby amino acids) in the so-called Nearest Neighbor (N-N) Methods. These methods increased the accuracy in many cases but still had strong limitations, as they only considered three possible states (helix, strand or turn). Moreover, as you know from the secondary structure practice, β-strands predictions are more difficult and did not improve much thanks to N-N methods. Additionally, predicted helices and strands were usually too short.\nBy the end of 1990 decade, new methods boosted the accuracy to values near to 80%. These methods included two innovations, one conceptual and one methodological. The conceptual innovation was the inclusion of evolutionary information in the predictions, by considering the information of multiple sequence alignments or profiles. If a residue or a type of residue is evolutionary conserved, it is likely that it is important to define SS stretches. The second innovation was the use of neural networks (see below) in which multiple layers of sequence-to-structure predictions were compared with a independently trained networks (see PHD paper by Burkhard Rost here).\nSince the 2000s, most commonly used methods are meta-servers that compare several algorithms, mostly based o neural-networks, like JPred or SYMPRED, among others.\nIn the recent years, deep neural networks trained with large datasets have become the primary method for protein secondary structure prediction (and almost any other prediction in StrBio). In the Alphafold era (see last lesson), methods adapted from image processing or natural language processing (NLP) are also used (for instance in NetSurfP-3.0, see Høie et al. (2022)), allowing protein secondary structure predictions to focus on specific objectives, such as enhancing the quality of evolutionary information for protein modeling (Ismi, Pulungan, and Afiahayati 2022).\n\nEvolution of secondary structure prediction methods (modified from Ismi, Pulungan, and Afiahayati (2022)).\n\n\n\n\n\n\n\nGeneration\nMethod\nAccuracy\n\n\n1st: Statistics\nChow & Fassman (1974-)\n57%\n\n\n\nGOR (1978-)\n\n\n\n2nd: Nearest Neighbor (N-N) methods\nPREDATOR (1996)\n75%\n\n\n\nNNSSP (1995)\n72%\n\n\n3rd: N-N neural network & evolutionary info\nAPSSP\nUp to 86%\n\n\n\nPsiPRED (1999-)\n75.7% (1999)\n84% (2019)\n\n\n\nPHD (1997)\n\n\n\n4th: Multiple layers of info\nExtra layers of info, such as conserved domains, frequent patterns, contact maps or predicted residue solvent accessibility (2000s)\n&lt;80%\n\n\n5th generation\nSophisticated deep learning architectures and NLP (2010s, 2020s).\nRaptorX-Property, (2018), SPIDER3 (2020) and NetSurfP-3.0 (2022), among others.\n&gt;80%\n\n\nMETA-Servers\nJpred4\n\n\n\n\nGeneSilico (Discontinued)\n\n\n\n\nSYMPRED"
  },
  {
    "objectID": "1d.html#structural-disorder-and-solvent-accessibility",
    "href": "1d.html#structural-disorder-and-solvent-accessibility",
    "title": "1D Features",
    "section": "Structural disorder and solvent accessibility",
    "text": "Structural disorder and solvent accessibility\nThe expression disorder denote protein stretches that cannot be assigned to any SS. They are usually dynamic/flexible, thus with high B-factor or even missing in crystal structures. These fragments show a low complexity and they are usually rich in polar residues, whereas aromatic residues are rarely found in disordered regions. These motifs are usually at the ends of proteins or domain boundaries (as linkers). Additionally, they are frequently related to specific functionalities, such in the case of proteolytic targets or protein-protein interactions (PPI). More rarely, large disordered domains can be conserved in protein families and associated with relevant functions, as in the case of some transcription factors, transcription regulators, kinases…\nThere are many methods and servers to predict disordered regions. You can see a list in the Wikipedia here or in the review by Atkins et al. (2015). The best-known server is DisProt, which uses a large curated database of intrinsically disordered proteins and regions from the literature, which has been recently improved to version 9 in 2022, as described in Quaglia et al. (2022).\nInterestingly, a low plDDT (see below) score in Alphafold2 models has been also suggested as a good indicator of protein disorder (Wilson, Choy, and Karttunen 2022).\n\n\n\nFigure 1: Examples of disordered regions. From Database of disordered regions.\n\n\nHydrophobic collapse is usually referred to as a key step in protein folding. Hydrophobic residues tend to be buried inside the protein, whereas hydrophilic, polar amino acids are exposed to the aqueous solvent.\n\n\n\nFigure 2: Hydrophobic collapse as a early step in protein folding. From Feenstra & Abeln, Introduction to Structural Bioinformatics.\n\n\nSolvent accessibility correlates with residue hydrofobicity \u000b(accessibility methods usually better \u000bperformance). Therefore, estimation of how likely each residue is exposed to the solvent or buried inside the protein is useful to obtain and analyze protein models. Moreover, this information is useful to predict PPIs as well as ligand binding or functional sites. Most methods only classify each residue into two groups: Buried, for those with relative accessibility probability &lt;16% and Exposed, for accessibility residues &gt;16%.\nMost common recent methods, like ProtSA or PROFacc, combine evolutionary information with neural networks to predict accessibility."
  },
  {
    "objectID": "1d.html#trans-membrane-motifs-and-membrane-topology",
    "href": "1d.html#trans-membrane-motifs-and-membrane-topology",
    "title": "1D Features",
    "section": "Trans-membrane motifs and membrane topology",
    "text": "Trans-membrane motifs and membrane topology\nIdentification of transmembrane motifs is also a key step in protein modeling. About 25-30% of human proteins contain transmembrane elements, most of them in alpha helices.\n\n\n\nFigure 3: Different topologies of transmembrane proteins\n\n\nThe PDBTM (Protein Data Bank of Transmembrane Proteins) is a comprehensive and up-to-date transmembrane protein selection. As of September 2022, it contains more than 7600 transmembrane proteins, 92.6% of them with alpha helices TM elements. This number of TM proteins is relatively low, as compared with more than 160k structures in PDB, as TM proteins are usually harder to purify and crystalization conditions are often elusive. Thus, although difficult, accurate predictions of TM motifs and overall protein topology can be essential to define protein architecture and identify domains that could be structurally or functionally studied independently.\n\n\n\nFigure 4: Different topologies of TM helices.\n\n\nCurrent state-of-the-art TM prediction protocols show an accuracy of 90% for definition of TM elements, but only a 80% regarding the protein topology. However, some authors claim that in some types of proteins, the accuracy is not over 70%, due to the small datasets of TM proteins. Most recent methods, based in deep-learning seem to have increased the accuracy to values near 90% for several groups of proteins (Hallgren et al. 2022)."
  },
  {
    "objectID": "1d.html#subcellular-localization-tags-and-post-translational-modification-sites",
    "href": "1d.html#subcellular-localization-tags-and-post-translational-modification-sites",
    "title": "1D Features",
    "section": "Subcellular localization tags and post-translational modification sites",
    "text": "Subcellular localization tags and post-translational modification sites\nMany cellular functions are compartmentalized in the nucleus, mitochondria, endoplasmatic reticulum (ER), or other organules. Therefore, many proteins should be located in those compartments. That is achieved by the presence of some labels, in form of short peptidic sequences that regulate traffic and compartmentalization of proteins within the cells. Typically, N-terminal signals direct proteins to the mitochondrial matrix, ER, or peroxisomes, whereas nucleus traffic is regulated by nuclear localization signals (NLS) and nuclear export signals (NES).\nSimilarly, post-translational modifications very often occur in conserved motifs that contain target residues for phosphorylation or ubiquitination, among other modifications.\nThese short motifs are difficult to predict, as datasets of validated signals are small. The use of consensus sequences allowed predictions, although in many cases with a high level of uncertainty."
  },
  {
    "objectID": "1d.html#multiple-state-of-secondary-structures",
    "href": "1d.html#multiple-state-of-secondary-structures",
    "title": "1D Features",
    "section": "Multiple state of secondary structures",
    "text": "Multiple state of secondary structures\nSecondary structures are assigned to structures using DSSP (Define Secondary Structure of Proteins) algorithm, originally written in 1983 and updated several times throughout the years, being the last version from 2021 (available on GitHub). This algorithm classifies each residue considering its geometry and H-bonds prediction by comparison with pre-existing patterns in DSSP database. Remarkably, DSSP does not predict secondary structures, it just extracts this information from the 3D coordinates.\nMost protein secondary structure prediction (PSSP) methods use a three-state secondary structure, in which the secondary structure elements consist of helix (H), sheet (E), and coil (C). Helix and sheet are the two main conformations suggested in early times of structural biology by Linus Pauling (see Intro Lesson), whereas Coil (C) denotes an amino acid that does not fit both H and E. This representation is very important and still used by many structural biologist, however it imposes several limitations that cannot be overlooked. This is because three secondary structure states are only a coarse-grained representation of the backbone structure with helical and sheet residues that very often can deviate from the standard helix and sheet conformations.\nAlready in the 80s, a eight-state secondary structure was proposed (see Ismi, Pulungan, and Afiahayati (2022)), consisting in α-helix (H), 310-helix (G), parallel/anti-parallel β-sheet (E), isolated β-bridge (B), bend (S), turn (T), π-helix (I) and coli (C). In fact, DSSP, defines the eight states in experimentally obtained structures and it also contains transformations that rule the mapping of eight-state secondary structures to the three-states.\nMore recently, in 2020, four-state and five-state PSSP were proposed to simplify predictions and increase the true-positives. The reason for proposing four-state and five-state PSSP was the imbalanced samples of each class: isolated β-bridge (B) and bend (S) have a small number of samples and low true-positive rates. In five-state PSSP, B and S are considered as C, whereas in four-state PSSP, B, S, and G are considered as C. Moreover, 75% of π-helix (I) was located at the beginning or the end of an a-helix structure (H), so it was categorized as H. The full potential of this new categories is still to be analyzed in detail"
  },
  {
    "objectID": "1d.html#evolution-of-prediction-methods",
    "href": "1d.html#evolution-of-prediction-methods",
    "title": "1D Features",
    "section": "Evolution of Prediction methods",
    "text": "Evolution of Prediction methods\nProtein secondary structure prediction (PSSP) from protein sequences is based in the hypothesis that Segments of consecutive residues have preferences for certain secondary structure states. Similar to other methods in bioinformatics, including protein modeling, approaches to SS prediction evolved during the last 50 years (see Table 1).\nFirst generation methods rely on statistics approaches and prediction depends on assigning a set of prediction values to a residue \u000band then applying a simple algorithm to those numbers. I.e. apply a probability score based on \u000bsingle amino acid propensity. In the 1990’s, new algorithms included the information of the flanking residues (3-50 nearby amino acids) in the so-called Nearest Neighbor (N-N) Methods. These methods increased the accuracy in many cases but still had strong limitations, as they only considered three possible states (helix, strand or turn). Moreover, as you know from the secondary structure practice, β-strands predictions are more difficult and did not improve much thanks to N-N methods. Additionally, predicted helices and strands were usually too short.\nBy the end of 1990 decade, new methods boosted the accuracy to values near to 80%. These methods included two innovations, one conceptual and one methodological. The conceptual innovation was the inclusion of evolutionary information in the predictions, by considering the information of multiple sequence alignments or profiles. If a residue or a type of residue is evolutionary conserved, it is likely that it is important to define SS stretches. The second innovation was the use of neural networks (see below) in which multiple layers of sequence-to-structure predictions were compared with a independently trained networks (see PHD paper by Burkhard Rost here).\nSince the 2000s, most commonly used methods are meta-servers that compare several algorithms, mostly based o neural-networks, like JPred or SYMPRED, among others.\nIn the recent years, deep neural networks trained with large datasets have become the primary method for protein secondary structure prediction (and almost any other prediction in StrBio). In the Alphafold era (see last lesson), methods adapted from image processing or natural language processing (NLP) are also used (for instance in NetSurfP-3.0, see Høie et al. (2022)), allowing protein secondary structure predictions to focus on specific objectives, such as enhancing the quality of evolutionary information for protein modeling (Ismi, Pulungan, and Afiahayati 2022).\n\nEvolution of secondary structure prediction methods (modified from Ismi, Pulungan, and Afiahayati (2022)).\n\n\n\n\n\n\n\nGeneration\nMethod\nAccuracy\n\n\n1st: Statistics\nChow & Fassman (1974-)\n57%\n\n\n\nGOR (1978-)\n\n\n\n2nd: Nearest Neighbor (N-N) methods\nPREDATOR (1996)\n75%\n\n\n\nNNSSP (1995)\n72%\n\n\n3rd: N-N neural network & evolutionary info\nAPSSP\nUp to 86%\n\n\n\nPsiPRED (1999-)\n75.7% (1999)\n84% (2019)\n\n\n\nPHD (1997)\n\n\n\n4th: Multiple layers of info\nExtra layers of info, such as conserved domains, frequent patterns, contact maps or predicted residue solvent accessibility (2000s)\n&lt;80%\n\n\n5th generation\nSophisticated deep learning architectures and NLP (2010s, 2020s).\nRaptorX-Property, (2018), SPIDER3 (2020) and NetSurfP-3.0 (2022), among others.\n&gt;80%\n\n\nMETA-Servers\nJpred4\n\n\n\n\nGeneSilico (Discontinued)\n\n\n\n\nSYMPRED"
  },
  {
    "objectID": "ai.html#now-what-the-post-alphafold-era",
    "href": "ai.html#now-what-the-post-alphafold-era",
    "title": "Protein modeling in the AlphaFold era",
    "section": "Now what? The Post-AlphaFold era",
    "text": "Now what? The Post-AlphaFold era\nAs mentioned earlier, RoseTTAFold was released at the same time as AlphaFold’s paper and code, although it is clearly inspired by AlphaFold’s capabilities in CASP14. It is based on a three-track network, and recent implementations have allowed prediction of protein interactions with nucleic acids. Other methods such as AlphaFold and RoseTTAFold were released later, as were OpenFold and UniFold, which are based on the PyTorch Transformers AI framework. More recently, RoseTTAFold2, which extends the three-track architecture over the whole network and incorporate other new advances and AlphaFold tricks, like the FAPE (frame aligned point error) or recycling steps during the training, giving rise to an end-to-end model equivalent in accuracy to AF2 for monomers and AF2-multimer for complexes, with better computational scaling on proteins and complexes larger than 1000 residues Baek et al. (n.d.).\nThe use of MSA has been cited as a limitation for AlphaFold and related methods. However, the predictions are significantly worse without MSA or with MSAs without depth. One way to improve predictions is to use a protein natural language model (PLN), i.e., a model trained to predict sequence from sequence and not dependent on good MSAs. Omegafold and ESMfold (also in Colabfold, here and here, respectively) are two new implementations that require only a single sequence. They are quite fast and perform better than AlphaFold when using a single sequence. However, since PLN is trained on existing sequences, these methods still perform significantly worse on orphan sequences. That is, the language models seem to just remember the training MSAs Elofsson (2023).\nThe appearance of ESMfold and the companion Metagenomic Atlas Lin et al. (2023) was seen as a new step that could trigger a new revolution in the field, since it was developed by scientists at META Callaway (2022). So it was now a sort of Google versus Facebook battle for the most powerful AI methods for protein modeling. Last summer, however, we learned that META had decided to discontinue the ESM project.\n\nAlphaFold was again the protagonist of CASP15, which took place in 2020, but it did not overwhelm the rest like in 2018.\n\nAlphaFold was used in some form in more than half of the protocols, and while the standard AlphaFold method performed better than many other methods, several groups achieved significant improvements for monomeric proteins and protein assemblies. In short (see Elofsson (2023)), we learned at CASP15 that there are two main ways to improve AlphaFold: (1) more efficient use of templates, increasing the size of the database or sampling through more efficient MSAs, or (2) hacking AlphaFold to use dropouts to generate thousands of models for each target, which increases computational time but also increases the chances of better models. Other small improvements have been proposed, such as refinement steps (Adiyaman et al. 2023) or using improved template search or new scoring capabilities based on Voronoi surfaces or Deep Learning.\n\n2021-2023 - Short summary in one  wire"
  },
  {
    "objectID": "ai.html#corollary-did-deepmind-fold-levinthals-paradox",
    "href": "ai.html#corollary-did-deepmind-fold-levinthals-paradox",
    "title": "Protein modeling in the AlphaFold era",
    "section": "Corollary: Did Deepmind “fold” Levinthal’s paradox?",
    "text": "Corollary: Did Deepmind “fold” Levinthal’s paradox?\nThe development of Alphafold and the Alphafold structures Database in collaboration with EMBL-EBI was been the origin of a New Era. Moreover, in a further turn, the Metagenomic Atlas by Meta AI uncovers virtually the whole protein space. Thanks to these milestones the coverage of the protein structure space has been greatly increased (Porta-Pardo et al. 2022), which virtually close the sequence-structure gap. Since 2020, many scientific publications and journals worldwide published long articles about the meaning of this breakthrough in science and its applications in biotechnology and biomedicine2 and DeepMind claimed to have Solved a 50-years Grand Challenge in biochemistry.\nIn other words, after AlphaFold, would it no longer be necessary to perform X-ray crystallography or nuclear magnetic resonance? First, AlphaFold models can be used in electron density maps and help solve complex cases. Thus, the new framework helps crystallographers focus their work on the most unresolved and difficult structures, such as coiled-coils or holoproteins, which cause modulations and challenges in the development of crystallographic methods.\nHowever, some scientists argued that Alphafold2 and RoseTTAfold actually cheat as they do not really solve the problem but generate a deep learning pipeline that is able to bypass the problem (Pederson 2021). In agreement with that, it has been shown that machine learning methods actually do not reproduce the expected folding pathways while improving the structures during the recycling steps Outeiral, Nissley, and Deane (n.d.).\nIn conclusion, I believe that the Levinthal paradox is not (yet) fully solved, although it seems to be close (Al-Janabi 2022). Practically, it is solved for most of the protein space, but if your protein does not have a homolog in the databases, you will still have some open questions."
  },
  {
    "objectID": "ai.html#why-is-alphafold-so-freaking-accurate",
    "href": "ai.html#why-is-alphafold-so-freaking-accurate",
    "title": "Protein modeling in the AlphaFold era",
    "section": "Why is Alphafold so freaking accurate?",
    "text": "Why is Alphafold so freaking accurate?\nThe philosophy behind Alphafold v.2 (from now on, just Alphafold) and related methods is to treat the protein folding problem as a machine learning problem, similar to image processing. In all of these problems, the input to the Deep Learning model is a volume (3D tensor). In the case of computer vision, 2D images expand as volumes because of the RGB or HSV channels. Similarly, in the case of distance prediction, predicted 1D and 2D features are transformed and packed into a 3D volume with many channels of inter-residue information (Pakhrin et al. 2021).\n\n\n\nFigure 5: From the perspective of Deep Learning method development, the problem of protein distogram or real-valued distance prediction (bottom row) is similar to the ‘depth prediction problem’ in computer vision. From Pakhrin et al. (2021).\n\n\nAlphafold can be explained as a pipeline with three interconected tasks (see picture below). First, in contrast to Alphafold v.1, the input to Alphafold is a “raw” MSA, i.e., the deep learning network extracts the co-evolutionary information directly from the MSA. It queries several databases of protein sequences and constructs an MSA that is used to select templates. This can be a limiting step, affecting the speed of modeling (see below), but it can be also related to model accuracy, as has been recently shown in CASP15 (Lee et al., n.d.; Peng et al. 2023).\nIn the second part of the diagram, AlphaFold takes the multiple sequence alignment and the templates, and processes them in a transformer. This process has been referred by some authors as inter-residue interaction map-threading (Bhattacharya et al. 2021). The objective of this part is to extract layers of information to generate residue interaction maps. A better model of the MSA will improve the network’s characterization of the geometry, which simultaneously will help refine the model of the MSA. Importantly, in the AF2 Evoformer, this process is iterative and the information goes back and forth throughout the network. At every recycling step, the complexity of the map increases and thus, the model improves (the original model uses 3 cycles). As explained in the great post from Carlos Outerial at the OPIG site:\n\nThis is easier to understand as an example. Suppose that you look at the multiple sequence alignment and notice a correlation between a pair of amino acids. Let’s call them A and B. You hypothesize that A and B are close, and translate this assumption into your model of the structure. Subsequently, you examine said model and observe that, since A and B are close, there is a good chance that C and D should be close. This leads to another hypothesis, based on the structure, which can be confirmed by searching for correlations between C and D in the MSA. By repeating this several times, you can build a pretty good understanding of the structure.\n\nThe third part of the pipeline is the structure building module, which uses the information from the previous steps to construct a 3D model structure protein of the query sequence. This network will give you a single model, without any energy optimization step. Model building is based in a new concept of 3D structures generation, named IPA (Invariant Point Attention) and the use of a curated list of parametrised list of torsion angles to generate the side chains. Earlier attempts to develop and end-to-end method were unsuccessful because the structure representation was not optimal. Even methods implemented after AlphaFold, like RoseTTAFold, use less efficient methods and often predict very quickly and accurately the backbone coordinates but require external programs to generate an all-atoms model\n\n\n\nFigure 6: Oxford Proteins Informatics Group Blog, modified from Jumper et al. (2021)\n\n\nLike for most of the previous methods Alphafold would give your better results with proteins with related structures known and with a lot of homologs in Uniref databases. However, comparing to nothing, it will likely give you (limited) useful results for the so-called “dark genome”. I work with phages and bacterial mobile elements, and sequencing that is often frustrating as more than 50% of the proteins have no homologous in the database. So you have a bunch of proteins of unknown function… However, as we do know that structure is more conserved than sequence, we may use the structure to find out the function of our dark proteins. There are a few resources for this, I’d suggest you to try FoldSeek (Kempen et al., n.d.) and Dali (Holm 2022) servers. You can upload the PDB file of your model and search for related structures in RCSB PDB database and also in Alphafold database.\n\n\n\n\n\n\nTip\n\n\n\nFoldSeek needs only a few seconds/minutes and is therefore faster than Dali. Therefore, it is better to use Dali for some selected searches that require a double check or a more reliable result, even if it may take a few days.\n\n\nAs mentioned above, Colabfold aims to make the process faster by using MMSeqs in the first block. Additionally, the number of recycling steps can also be adapted. Moreover, different Colabfold notebooks have been developed (and evolved) to allow some customization and other feature, like batch processing of multiple proteins avoiding recompilation and identification of protein-protein interactions (Mirdita et al. 2022).\nAlphafold models can be evaluated by the mean pLDDT, a per-residue confidence metric. It is stored in the B-factor fields of the mmCIF and PDB files available for download (although unlike a B-factor, higher pLDDT is better). The model confidence can vary greatly along a chain so it is important to consult the confidence when interpreting structural features. Very often, the lower confidence fragments are not product of a poor prediction but an indicator of protein disorder (Wilson, Choy, and Karttunen 2022).\nAlphafold also partnered with EMBL-EBI and Uniprot and generated a huge curated database of proteins from model organisms (Varadi et al. 2022), the Alphafold database. This is an amazing resource that may be also very helpful for you. Just consider that this database increased from 48% to 76% the fraction of human proteome with structural data, and also it also means great increases in the case of other model organisms, like, including microorganisms and plants (Porta-Pardo et al. 2022).\n\n\n\nFigure 7: Changes in protein structural coverage in model organisms (From Porta-Pardo et al. (2022))."
  },
  {
    "objectID": "homology.html#alphafold-db-models",
    "href": "homology.html#alphafold-db-models",
    "title": "Homology Modeling",
    "section": "AlphaFold DB models",
    "text": "AlphaFold DB models\nModels from the AlphaFold DB are appended to the available structures / models if available. For these models we use the confidence values provided by AlphaFold (pLDDT) rescaled to be between 0 and 1. Since both pLDDT and QMEANDisCo are trained to predict lDDT (Cα-only for pLDDT and all-atom for QMEANDisCo) and are displayed in the same range, they should be considered comparable (From https://swissmodel.expasy.org/docs/repository_help)"
  },
  {
    "objectID": "bims_exercise.html",
    "href": "bims_exercise.html",
    "title": "BIBMS-3: StrBio Exercise",
    "section": "",
    "text": "The goal of this exercise1 is to learn how to work with protein structures, analyze them, and understand the differences between different structures. Follow the indicated steps and then answer the questions in Moodle.\nQuestions are very welcome, but please use the Moodle Q&A to allow your classmates see the discussions."
  },
  {
    "objectID": "bims_exercise.html#footnotes",
    "href": "bims_exercise.html#footnotes",
    "title": "BIBMS-3: StrBio Exercise",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis exercise is inspired in the “Homology Modeling” exercise in the Course Bioinformatics & Molecular Biology by Department of Molecular Biosciences and Department of Informatics at the University of Oslo (UiO). However, this is a shorter and updated version adapted for BIBMS@UAM. Please let me know if you find any mistake or trouble.↩︎"
  }
]